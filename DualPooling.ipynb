{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57970c53-6cbb-473f-81fa-a942e2e493c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 셋팅 & 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbc8e70-853a-4f5f-b714-b83d5140097a",
   "metadata": {},
   "source": [
    "https://github.com/minsuk-sung/intel-image-classification/blob/master/Lecture06%20-%20CIFAR100.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3327b2f1-3de4-4973-8474-f474ad59fcdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4c6174b-bec3-4384-82f2-0ddf972aab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100\n",
    "from keras import models, layers\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers, initializers, regularizers, metrics\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Input, BatchNormalization, Conv2D, Activation, Dense, GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D, Add, Lambda\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical,plot_model\n",
    "from tensorflow.keras.losses import categorical_crossentropy,binary_crossentropy\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "\n",
    "from tensorflow.keras.utils import get_custom_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8a93f2a-b9d2-4a71-afba-1e242e161ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw\n",
    "from IPython.display import SVG\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.etree.ElementTree import Element, ElementTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a392079b-5651-4adc-8e62-f733bef69d8f",
   "metadata": {},
   "source": [
    "# Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64375f2e-c7d5-41c6-80d9-8ade8cde1180",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mphd1150\u001b[0m (\u001b[33mdiplab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a81b2d6-9572-4074-8719-526e5f4b56a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/diplab/DualPooing_Mac/runs/3r4niog2\" target=\"_blank\">MinPooing</a></strong> to <a href=\"https://wandb.ai/diplab/DualPooing_Mac\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/diplab/DualPooing_Mac/runs/3r4niog2?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x16a9f0e50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='DualPooing_Mac', name='MinPooing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e72d996-4377-455d-8999-b55aee7b42eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config = {\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epoch\": 60,\n",
    "    \"batch_size\": 32\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0b356fc-a9bf-4d80-885f-2e3c6cc217e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwandb.log({\"loss\": 0.314, \"epoch\": 50,\\n           \"inputs\": wandb.Image(inputs),\\n           \"logits\": wandb.Histogram(ouputs),\\n           \"captions\": wandb.Html(captions)})\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "wandb.log({\"loss\": 0.314, \"epoch\": 50,\n",
    "           \"inputs\": wandb.Image(inputs),\n",
    "           \"logits\": wandb.Histogram(ouputs),\n",
    "           \"captions\": wandb.Html(captions)})\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7feb0a-42c4-4543-8f3e-2e67e9b0ef96",
   "metadata": {},
   "source": [
    "# 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2ec7c13-96cd-482c-907c-1d54343c1b69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test,y_test) = cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f52a76c9-8102-4dce-96a0-2657fd973a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 길이:  100\n"
     ]
    }
   ],
   "source": [
    "CIFAR100_CLASSES = sorted(['beaver', 'dolphin', 'otter', 'seal', 'whale',  # aquatic mammals\n",
    "                           'aquarium' 'fish', 'flatfish', 'ray', 'shark', 'trout',  # fish\n",
    "                           'orchids', 'poppies', 'roses', 'sunflowers', 'tulips', # flowers\n",
    "                           'bottles', 'bowls', 'cans', 'cups', 'plates', # food containers\n",
    "                           'apples', 'mushrooms', 'oranges', 'pears', 'sweet peppers', # fruit and vegetables\n",
    "                           'clock', 'computer' 'keyboard', 'lamp', 'telephone', 'television', # household electrical devices\n",
    "                           'bed', 'chair', 'couch', 'table', 'wardrobe', # household furniture\n",
    "                           'bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach', # insects\n",
    "                           'bear', 'leopard', 'lion', 'tiger', 'wolf', # large carnivores\n",
    "                           'bridge', 'castle', 'house', 'road', 'skyscraper', # large man-made outdoor things\n",
    "                           'cloud', 'forest', 'mountain', 'plain', 'sea', # large natural outdoor scenes\n",
    "                           'camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo', # large omnivores and herbivores\n",
    "                           'fox', 'porcupine', 'possum', 'raccoon', 'skunk', # medium-sized mammals\n",
    "                           'crab', 'lobster', 'snail', 'spider', 'worm', # non-insect invertebrates\n",
    "                           'baby', 'boy', 'girl', 'man', 'woman', # people\n",
    "                           'crocodile', 'dinosaur', 'lizard', 'snake', 'turtle', # reptiles\n",
    "                           'hamster', 'mouse', 'rabbit', 'shrew', 'squirrel', # small mammals\n",
    "                           'maple', 'oak', 'palm', 'pine', 'willow', # trees\n",
    "                           'bicycle', 'bus', 'motorcycle', 'pickup truck', 'train', # vehicles 1\n",
    "                           'lawn-mower', 'rocket', 'streetcar', 'tank', 'tractor' # vehicles 2\n",
    "                          ])\n",
    "print('클래스 길이: ',len(CIFAR100_CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fbfbd1f-3fa8-4851-8d0f-2bcd665a9b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_valid,y_train,y_valid = train_test_split(X_train,y_train,test_size=0.2,shuffle=True,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98c41737-1cfd-436e-b815-b35651230f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-100 Train 데이터의 크기 : 40000\n",
      "CIFAR-100 Validation 데이터의 크기 : 10000\n",
      "CIFAR-100 Test 데이터의 크기 : 10000\n"
     ]
    }
   ],
   "source": [
    "print('CIFAR-100 Train 데이터의 크기 : {}'.format(len(X_train)))\n",
    "print('CIFAR-100 Validation 데이터의 크기 : {}'.format(len(X_valid)))\n",
    "print('CIFAR-100 Test 데이터의 크기 : {}'.format(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3f3f9b9-ff3d-47b7-95fd-fb2abd9593b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape :  (40000, 32, 32, 3)\n",
      "y_train Shape :  (40000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train Shape : \",X_train.shape) # 32*32짜리 크기의 RGB 이미지 40000개\n",
    "print(\"y_train Shape : \",y_train.shape) # 각 이미지별 레이블 40000개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7635499e-c4e6-4fdc-a1bc-fbb8ea1eb0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 0\n",
    "\n",
    "plt.imshow(X_train[idx], interpolation='nearest')\n",
    "plt.title('Label : {}'.format(CIFAR100_CLASSES[y_train[idx][0]]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35a1b397-d765-43ea-be11-14ba0b5eae82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 32, 3)\n",
      "(40000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_train = X_train.reshape(X_train.shape[0],32,32,3)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46207a1c-3fb0-4158-8659-c1d1914edc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a95682f4-5c38-4a5c-b637-1c1d04224dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 재연성을 위하여 랜덤시드 고정\n",
    "np.random.seed(1234) \n",
    "\n",
    "# random 함수를 통해서 임의의 16개 데이터 가져오기\n",
    "samples = np.random.randint(0,len(X_train)+1,size=6)\n",
    "\n",
    "# MNIST를 그릴 Figure 준비\n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "# 16개의 이미지 시각화\n",
    "for count, n in enumerate(samples,start=1):\n",
    "    plt.subplot(2, 3, count)\n",
    "    plt.imshow(X_train[n], interpolation='nearest')\n",
    "    label_name = \"Label:\" + str(CIFAR100_CLASSES[y_train[n][0]])\n",
    "    plt.title(label_name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d3b6a45-8b78-4a4f-8757-dd46bb073433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 크기 조정(Data Reshape)\n",
    "X_train = X_train.reshape(X_train.shape[0],32,32,3)\n",
    "X_valid = X_valid.reshape(X_valid.shape[0],32,32,3)\n",
    "X_test = X_test.reshape(X_test.shape[0],32,32,3)\n",
    "\n",
    "# 데이터 포맷 바꾸기\n",
    "# 정수(int)인 데이터에서 실수(float)으로 변환\n",
    "X_train = X_train.astype('float32')\n",
    "X_valid = X_valid.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# 데이터 정규화(Data Regularization)\n",
    "# 이 과정을 통해서 추후 학습할 신경망이 조금 더 학습이 원할히 될 수 있게함\n",
    "X_train = X_train / 255\n",
    "X_valid = X_valid / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# 원-핫 인코딩(One Hot Encoding)\n",
    "# Keras의 to_categorical함수를 통해서 모든 Train 데이터의 레이블을 벡터화(Vectorize)\n",
    "# ex) [3] -> [0 0 0 1 0 0 0 0 0 0]\n",
    "y_train = to_categorical(y_train, 100) \n",
    "y_valid = to_categorical(y_valid,100)\n",
    "y_test = to_categorical(y_test, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6563316e-fb81-4619-9772-fc13bbd217f6",
   "metadata": {},
   "source": [
    "# Custom Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9a907941-3538-4dfd-8cd5-6d9794c02022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_pool(x):\n",
    "    print('x_shape: ',x.shape)\n",
    "    n_channel = x.shape[-1]\n",
    "    \n",
    "    patches = tf.image.extract_patches(x,\n",
    "                                       sizes = [1, 2, 2, 1], \n",
    "                                       strides = [1, 2, 2, 1], \n",
    "                                       rates = 4*[1],\n",
    "                                       padding = 'SAME')\n",
    "    \n",
    "    channel_pool = [tf.reduce_min(patches[:,:,:,c::n_channel], keepdims=True, axis=-1) for c in range(n_channel)]\n",
    "    \n",
    "    return tf.concat(channel_pool, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fbf4e7-82ae-4614-a11c-5df4d1cc4fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def min_pool_2(x):\n",
    "    # print('x_shape: ',x.shape)\n",
    "    n_channel = x.shape[-1]\n",
    "    \n",
    "    B = x.shape[0]\n",
    "    w = x.shape[1]\n",
    "    h = x.shape[2]\n",
    "    # print('B, w, h, C: ',B,w,h,n_channel)\n",
    "    \n",
    "    \n",
    "    patches = tf.image.extract_patches(x,\n",
    "                                       sizes = [1, 2, 2, 1], \n",
    "                                       strides = [1, 2, 2, 1], \n",
    "                                       rates = 4*[1],\n",
    "                                       padding = 'SAME')\n",
    "    \n",
    "    patches = tf.reshape(patches, shape = (-1, w//2, h//2, 2, 2, n_channel))\n",
    "\n",
    "    pooling = tf.reduce_min(patches, axis = [-3,-2])\n",
    "\n",
    "    return pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "045564cc-b094-44b0-89f9-e68c6f250d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinPooling(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(MinPooling, self).__init__()\n",
    "\n",
    "    def call(self, x):\n",
    "        result = min_pool_2(x)\n",
    "        \n",
    "        return result        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44e60b5e-2e76-4233-9826-930116bdf4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inv_Relu(Activation):\n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super(Inv_Relu, self).__init__(activation, **kwargs)\n",
    "        self.__name__ = 'inv_Relu'\n",
    "\n",
    "def inv_Relu(x):    \n",
    "    return tf.math.minimum(x, 0)\n",
    "\n",
    "get_custom_objects().update({'inv_Relu': Inv_Relu(inv_Relu)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603fff6d-7d09-406f-b969-0802b6682b4e",
   "metadata": {},
   "source": [
    "# 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5606dc-82f0-4a07-b600-79d2e2758ac9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### MaxPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cbde4ef5-f06b-46c4-9e16-36b4264ea910",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_vgg_block(input_layer,\n",
    "                    num_cnn=3, # conv 필터 개수 (여기선 2 or 3)\n",
    "                    channel=64,\n",
    "                    block_num=1,\n",
    "                   ):\n",
    "    \n",
    "    # 입력 레이어\n",
    "    x = input_layer # type(x) : <class 'keras.engine.keras_tensor.KerasTensor'>\n",
    "    \n",
    "    # CNN 레이어\n",
    "    for cnn_layer in range(num_cnn):        \n",
    "        x = layers.Conv2D(filters=channel,\n",
    "                          kernel_size=(3,3),\n",
    "                          activation=None,\n",
    "                          # kernel_initializer='he_normal',\n",
    "                          padding='same',\n",
    "                          name=f'Max_block{block_num}_conv{cnn_layer}'\n",
    "                         )(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.nn.relu(x)\n",
    "    # Max Pooling 레이어\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2),\n",
    "                            strides=2,\n",
    "                            name=f'Max_block{block_num}_pooling'\n",
    "                           )(x)\n",
    "    \n",
    "    #x = BatchNormalization()(x)\n",
    "    \n",
    "    return x        \n",
    "\n",
    "def build_vgg(input_shape=(32,32,3),\n",
    "              num_cnn_list=[2,2,3,3],\n",
    "              channel_list=[64,128,256,512],\n",
    "              num_classes=100):\n",
    "    \n",
    "    assert len(num_cnn_list) == len(channel_list), '길이가 다르다' # 블럭의 개수가 됨. 둘이 같은지 점검하는 코드\n",
    "    \n",
    "    input_layer = Input(shape=input_shape) # input layer 생성\n",
    "    output = input_layer\n",
    "    \n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        output = build_vgg_block(output,\n",
    "                                 num_cnn=num_cnn,\n",
    "                                 channel=channel,\n",
    "                                 block_num=i\n",
    "                                )\n",
    "    \n",
    "    output = layers.Flatten(name='Max_flatten')(output)\n",
    "    # output = BatchNormalization()(output)\n",
    "    output = layers.Dense(512, activation=None,name='Max_fc1')(output)\n",
    "    output = BatchNormalization()(output)\n",
    "    output = tf.nn.relu(output)\n",
    "    output = layers.Dense(512, activation=None,name='Max_fc2')(output)\n",
    "    output = BatchNormalization()(output)\n",
    "    output = tf.nn.relu(output)\n",
    "    output = layers.Dense(num_classes, activation='softmax',name='Max_predictions')(output)\n",
    "    \n",
    "    model = Model(inputs=input_layer,\n",
    "                        outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9731e51a-96c6-4546-9e29-bc397a6efa1a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " Max_block0_conv0 (Conv2D)   (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " batch_normalization_46 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " tf.nn.relu_22 (TFOpLambda)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " Max_block0_conv1 (Conv2D)   (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_47 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " tf.nn.relu_23 (TFOpLambda)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " Max_block0_pooling (MaxPool  (None, 16, 16, 64)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Max_block1_conv0 (Conv2D)   (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_48 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " tf.nn.relu_24 (TFOpLambda)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " Max_block1_conv1 (Conv2D)   (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_49 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " tf.nn.relu_25 (TFOpLambda)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " Max_block1_pooling (MaxPool  (None, 8, 8, 128)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Max_block2_conv0 (Conv2D)   (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_50 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " tf.nn.relu_26 (TFOpLambda)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " Max_block2_conv1 (Conv2D)   (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_51 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " tf.nn.relu_27 (TFOpLambda)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " Max_block2_conv2 (Conv2D)   (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_52 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " tf.nn.relu_28 (TFOpLambda)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " Max_block2_pooling (MaxPool  (None, 4, 4, 256)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Max_block3_conv0 (Conv2D)   (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " batch_normalization_53 (Bat  (None, 4, 4, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " tf.nn.relu_29 (TFOpLambda)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " Max_block3_conv1 (Conv2D)   (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_54 (Bat  (None, 4, 4, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " tf.nn.relu_30 (TFOpLambda)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " Max_block3_conv2 (Conv2D)   (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_55 (Bat  (None, 4, 4, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " tf.nn.relu_31 (TFOpLambda)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " Max_block3_pooling (MaxPool  (None, 2, 2, 512)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Max_flatten (Flatten)       (None, 2048)              0         \n",
      "                                                                 \n",
      " Max_fc1 (Dense)             (None, 512)               1049088   \n",
      "                                                                 \n",
      " batch_normalization_56 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " tf.nn.relu_32 (TFOpLambda)  (None, 512)               0         \n",
      "                                                                 \n",
      " Max_fc2 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_57 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " tf.nn.relu_33 (TFOpLambda)  (None, 512)               0         \n",
      "                                                                 \n",
      " Max_predictions (Dense)     (None, 100)               51300     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,013,156\n",
      "Trainable params: 9,005,732\n",
      "Non-trainable params: 7,424\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_16 = build_vgg()\n",
    "vgg_16.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2252be82-bcec-4998-bfa7-8034450ca6c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### MinPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68aa2240-ad6e-4b03-936b-2c42b4893739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def M_build_vgg_block(input_layer,\n",
    "                    num_cnn=3, # conv 필터 개수 (여기선 2 or 3)\n",
    "                    channel=64,\n",
    "                    block_num=1,\n",
    "                   ):\n",
    "    \n",
    "    # 입력 레이어\n",
    "    x = input_layer # type(x) : <class 'keras.engine.keras_tensor.KerasTensor'>\n",
    "    \n",
    "    # CNN 레이어\n",
    "    for cnn_layer in range(num_cnn):        \n",
    "        x = layers.Conv2D(filters=channel,\n",
    "                          kernel_size=(3,3),\n",
    "                          activation=None,\n",
    "                          # kernel_initializer='he_normal',\n",
    "                          padding='same',\n",
    "                          name=f'Min_block{block_num}_conv{cnn_layer}'\n",
    "                         )(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('inv_Relu')(x)\n",
    "    # 변경점\n",
    "    # Min Pooling 레이어\n",
    "    x = MinPooling()(x) # 클래스 선언 + call ?\n",
    "    \n",
    "    # x = BatchNormalization()(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def M_build_vgg(input_shape=(32,32,3),\n",
    "              num_cnn_list=[2,2,3,3],\n",
    "              channel_list=[64,128,256,512],\n",
    "              num_classes=100):\n",
    "    \n",
    "    assert len(num_cnn_list) == len(channel_list), '길이가 다르다' # 블럭의 개수가 됨. 둘이 같은지 점검하는 코드\n",
    "    \n",
    "    input_layer = Input(shape=input_shape) # input layer 생성\n",
    "    output = input_layer\n",
    "    \n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        output = M_build_vgg_block(output,\n",
    "                                 num_cnn=num_cnn,\n",
    "                                 channel=channel,\n",
    "                                 block_num=i\n",
    "                                )\n",
    "    \n",
    "    output = layers.Flatten(name='Min_flatten')(output)\n",
    "    # x = BatchNormalization()(x)\n",
    "    output = layers.Dense(512, activation=None,name='Min_fc1')(output)\n",
    "    output = BatchNormalization()(output)\n",
    "    output = Activation('inv_Relu')(output)\n",
    "    output = layers.Dense(512, activation=None,name='Min_fc2')(output)\n",
    "    output = BatchNormalization()(output)\n",
    "    output = Activation('inv_Relu')(output)\n",
    "    output = layers.Dense(num_classes, activation='softmax',name='Min_predictions')(output)\n",
    "    \n",
    "    model = Model(inputs=input_layer,\n",
    "                        outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a621999-6e92-4605-b90a-1a00fc6744d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 12:37:12.565171: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-10-13 12:37:12.565278: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " Min_block0_conv0 (Conv2D)   (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " Min_block0_conv1 (Conv2D)   (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 32, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " min_pooling (MinPooling)    (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " Min_block1_conv0 (Conv2D)   (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " Min_block1_conv1 (Conv2D)   (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " min_pooling_1 (MinPooling)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " Min_block2_conv0 (Conv2D)   (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " Min_block2_conv1 (Conv2D)   (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " Min_block2_conv2 (Conv2D)   (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " min_pooling_2 (MinPooling)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " Min_block3_conv0 (Conv2D)   (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 4, 4, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " Min_block3_conv1 (Conv2D)   (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 4, 4, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " Min_block3_conv2 (Conv2D)   (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 4, 4, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " min_pooling_3 (MinPooling)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " Min_flatten (Flatten)       (None, 2048)              0         \n",
      "                                                                 \n",
      " Min_fc1 (Dense)             (None, 512)               1049088   \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 512)               0         \n",
      "                                                                 \n",
      " Min_fc2 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 512)               0         \n",
      "                                                                 \n",
      " Min_predictions (Dense)     (None, 100)               51300     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,013,156\n",
      "Trainable params: 9,005,732\n",
      "Non-trainable params: 7,424\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "M_vgg_16 = M_build_vgg()\n",
    "M_vgg_16.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0818ad89-5e7f-4cf1-ab28-ca817221bea1",
   "metadata": {},
   "source": [
    "### Dual Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0db2ee69-e5a1-442d-b617-7eee108c834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type 1 (Add)\n",
    "def D_build_vgg(input_shape=(32,32,3),\n",
    "              num_cnn_list=[2,2,3,3],\n",
    "              channel_list=[64,128,256,512],\n",
    "              num_classes=100):\n",
    "    \n",
    "    assert len(num_cnn_list) == len(channel_list), '길이가 다르다' # 블럭의 개수가 됨. 둘이 같은지 점검하는 코드\n",
    "    \n",
    "    input_layer = Input(shape=input_shape) # input layer 생성\n",
    "    output1 = input_layer\n",
    "    output2 = input_layer\n",
    "    \n",
    "    # Max\n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        output1 = build_vgg_block(output1,\n",
    "                                 num_cnn=num_cnn,\n",
    "                                 channel=channel,\n",
    "                                 block_num=i\n",
    "                                )\n",
    "    \n",
    "    output1 = layers.Flatten(name='Max_flatten')(output1)\n",
    "    output1 = layers.Dense(512, activation='relu',name='Max_fc1')(output1)\n",
    "    output1 = layers.Dense(512, activation='relu',name='Max_fc2')(output1)\n",
    "    # output1 = layers.Dense(num_classes, activation='softmax',name='Max_predictions')(output1)\n",
    "    \n",
    "    # Min\n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        output2 = M_build_vgg_block(output2,\n",
    "                                 num_cnn=num_cnn,\n",
    "                                 channel=channel,\n",
    "                                 block_num=i\n",
    "                                )\n",
    "    \n",
    "    output2 = layers.Flatten(name='Min_flatten')(output2)\n",
    "    output2 = layers.Dense(512, activation='relu',name='Min_fc1')(output2)\n",
    "    output2 = layers.Dense(512, activation='relu',name='Min_fc2')(output2)\n",
    "    # output2 = layers.Dense(num_classes, activation='softmax',name='Min_predictions')(output2)\n",
    "    \n",
    "    # 결합부\n",
    "    # 1\n",
    "    # output = Add()([output1, output2])\n",
    "    # 2\n",
    "    output = tf.concat([output1, output2], 1)\n",
    "    \n",
    "    output = layers.Dense(num_classes, activation='softmax',name='predictions')(output)\n",
    "    model = Model(inputs=input_layer,\n",
    "                        outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2cbca965-0126-4cb2-a392-40139ad7d9e5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " Max_block0_conv0 (Conv2D)      (None, 32, 32, 64)   1792        ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " Min_block0_conv0 (Conv2D)      (None, 32, 32, 64)   1792        ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " Max_block0_conv1 (Conv2D)      (None, 32, 32, 64)   36928       ['Max_block0_conv0[0][0]']       \n",
      "                                                                                                  \n",
      " Min_block0_conv1 (Conv2D)      (None, 32, 32, 64)   36928       ['Min_block0_conv0[0][0]']       \n",
      "                                                                                                  \n",
      " Max_block0_pooling (MaxPooling  (None, 16, 16, 64)  0           ['Max_block0_conv1[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)              (None, 16, 16, 64)   0           ['Min_block0_conv1[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 16, 16, 64)  256         ['Max_block0_pooling[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 16, 16, 64)  256         ['lambda_4[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " Max_block1_conv0 (Conv2D)      (None, 16, 16, 128)  73856       ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " Min_block1_conv0 (Conv2D)      (None, 16, 16, 128)  73856       ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " Max_block1_conv1 (Conv2D)      (None, 16, 16, 128)  147584      ['Max_block1_conv0[0][0]']       \n",
      "                                                                                                  \n",
      " Min_block1_conv1 (Conv2D)      (None, 16, 16, 128)  147584      ['Min_block1_conv0[0][0]']       \n",
      "                                                                                                  \n",
      " Max_block1_pooling (MaxPooling  (None, 8, 8, 128)   0           ['Max_block1_conv1[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " lambda_5 (Lambda)              (None, 8, 8, 128)    0           ['Min_block1_conv1[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 8, 8, 128)   512         ['Max_block1_pooling[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 8, 8, 128)   512         ['lambda_5[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " Max_block2_conv0 (Conv2D)      (None, 8, 8, 256)    295168      ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " Min_block2_conv0 (Conv2D)      (None, 8, 8, 256)    295168      ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " Max_block2_conv1 (Conv2D)      (None, 8, 8, 256)    590080      ['Max_block2_conv0[0][0]']       \n",
      "                                                                                                  \n",
      " Min_block2_conv1 (Conv2D)      (None, 8, 8, 256)    590080      ['Min_block2_conv0[0][0]']       \n",
      "                                                                                                  \n",
      " Max_block2_conv2 (Conv2D)      (None, 8, 8, 256)    590080      ['Max_block2_conv1[0][0]']       \n",
      "                                                                                                  \n",
      " Min_block2_conv2 (Conv2D)      (None, 8, 8, 256)    590080      ['Min_block2_conv1[0][0]']       \n",
      "                                                                                                  \n",
      " Max_block2_pooling (MaxPooling  (None, 4, 4, 256)   0           ['Max_block2_conv2[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " lambda_6 (Lambda)              (None, 4, 4, 256)    0           ['Min_block2_conv2[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 4, 4, 256)   1024        ['Max_block2_pooling[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 4, 4, 256)   1024        ['lambda_6[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " Max_block3_conv0 (Conv2D)      (None, 4, 4, 512)    1180160     ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " Min_block3_conv0 (Conv2D)      (None, 4, 4, 512)    1180160     ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " Max_block3_conv1 (Conv2D)      (None, 4, 4, 512)    2359808     ['Max_block3_conv0[0][0]']       \n",
      "                                                                                                  \n",
      " Min_block3_conv1 (Conv2D)      (None, 4, 4, 512)    2359808     ['Min_block3_conv0[0][0]']       \n",
      "                                                                                                  \n",
      " Max_block3_conv2 (Conv2D)      (None, 4, 4, 512)    2359808     ['Max_block3_conv1[0][0]']       \n",
      "                                                                                                  \n",
      " Min_block3_conv2 (Conv2D)      (None, 4, 4, 512)    2359808     ['Min_block3_conv1[0][0]']       \n",
      "                                                                                                  \n",
      " Max_block3_pooling (MaxPooling  (None, 2, 2, 512)   0           ['Max_block3_conv2[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " lambda_7 (Lambda)              (None, 2, 2, 512)    0           ['Min_block3_conv2[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 2, 2, 512)   2048        ['Max_block3_pooling[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 2, 2, 512)   2048        ['lambda_7[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " Max_flatten (Flatten)          (None, 2048)         0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " Min_flatten (Flatten)          (None, 2048)         0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " Max_fc1 (Dense)                (None, 512)          1049088     ['Max_flatten[0][0]']            \n",
      "                                                                                                  \n",
      " Min_fc1 (Dense)                (None, 512)          1049088     ['Min_flatten[0][0]']            \n",
      "                                                                                                  \n",
      " Max_fc2 (Dense)                (None, 512)          262656      ['Max_fc1[0][0]']                \n",
      "                                                                                                  \n",
      " Min_fc2 (Dense)                (None, 512)          262656      ['Min_fc1[0][0]']                \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 1024)         0           ['Max_fc2[0][0]',                \n",
      "                                                                  'Min_fc2[0][0]']                \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 100)          102500      ['tf.concat[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18,004,196\n",
      "Trainable params: 18,000,356\n",
      "Non-trainable params: 3,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "D_vgg_16 = D_build_vgg()\n",
    "D_vgg_16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a08d5dc-d341-4792-b20e-18edcedbc990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type 2 (Concat)\n",
    "def D2_build_vgg(input_shape=(32,32,3),\n",
    "              num_cnn_list=[2,2,3,3],\n",
    "              channel_list=[64,128,256,512],\n",
    "              num_classes=100):\n",
    "    \n",
    "    assert len(num_cnn_list) == len(channel_list), '길이가 다르다' # 블럭의 개수가 됨. 둘이 같은지 점검하는 코드\n",
    "    \n",
    "    input_layer = Input(shape=input_shape) # input layer 생성\n",
    "    output1 = input_layer\n",
    "    output2 = input_layer\n",
    "    \n",
    "    # Max\n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        output1 = build_vgg_block(output1,\n",
    "                                 num_cnn=num_cnn,\n",
    "                                 channel=channel,\n",
    "                                 block_num=i\n",
    "                                )\n",
    "    \n",
    "    # Min\n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        output2 = M_build_vgg_block(output2,\n",
    "                                 num_cnn=num_cnn,\n",
    "                                 channel=channel,\n",
    "                                 block_num=i\n",
    "                                )\n",
    "    \n",
    "    # 결합부    \n",
    "    output = tf.concat([output1, output2], -1)\n",
    "    output = layers.Flatten(name='Dual_flatten')(output)\n",
    "    output = layers.Dense(512, activation=None,name='Dual_fc1')(output)\n",
    "    output = BatchNormalization()(output)\n",
    "    output = Activation('inv_Relu')(output)\n",
    "    output = layers.Dense(512, activation=None,name='Dual_fc2')(output)    \n",
    "    output = BatchNormalization()(output)\n",
    "    output = Activation('inv_Relu')(output)\n",
    "    output = layers.Dense(num_classes, activation='softmax',name='predictions')(output)\n",
    "    model = Model(inputs=input_layer,\n",
    "                        outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4a11323-c5ba-49c5-9a12-141511071c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " Max_block0_conv0 (Conv2D)      (None, 32, 32, 64)   1792        ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " Min_block0_conv0 (Conv2D)      (None, 32, 32, 64)   1792        ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 32, 32, 64)  256         ['Max_block0_conv0[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 32, 32, 64)  256         ['Min_block0_conv0[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.nn.relu_34 (TFOpLambda)     (None, 32, 32, 64)   0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " Max_block0_conv1 (Conv2D)      (None, 32, 32, 64)   36928       ['tf.nn.relu_34[0][0]']          \n",
      "                                                                                                  \n",
      " Min_block0_conv1 (Conv2D)      (None, 32, 32, 64)   36928       ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 32, 32, 64)  256         ['Max_block0_conv1[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 32, 32, 64)  256         ['Min_block0_conv1[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.nn.relu_35 (TFOpLambda)     (None, 32, 32, 64)   0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " Max_block0_pooling (MaxPooling  (None, 16, 16, 64)  0           ['tf.nn.relu_35[0][0]']          \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " lambda_12 (Lambda)             (None, 16, 16, 64)   0           ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " Max_block1_conv0 (Conv2D)      (None, 16, 16, 128)  73856       ['Max_block0_pooling[0][0]']     \n",
      "                                                                                                  \n",
      " Min_block1_conv0 (Conv2D)      (None, 16, 16, 128)  73856       ['lambda_12[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 16, 16, 128)  512        ['Max_block1_conv0[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 16, 16, 128)  512        ['Min_block1_conv0[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.nn.relu_36 (TFOpLambda)     (None, 16, 16, 128)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 16, 16, 128)  0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " Max_block1_conv1 (Conv2D)      (None, 16, 16, 128)  147584      ['tf.nn.relu_36[0][0]']          \n",
      "                                                                                                  \n",
      " Min_block1_conv1 (Conv2D)      (None, 16, 16, 128)  147584      ['activation_38[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 16, 16, 128)  512        ['Max_block1_conv1[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 16, 16, 128)  512        ['Min_block1_conv1[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.nn.relu_37 (TFOpLambda)     (None, 16, 16, 128)  0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 16, 16, 128)  0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " Max_block1_pooling (MaxPooling  (None, 8, 8, 128)   0           ['tf.nn.relu_37[0][0]']          \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " lambda_13 (Lambda)             (None, 8, 8, 128)    0           ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " Max_block2_conv0 (Conv2D)      (None, 8, 8, 256)    295168      ['Max_block1_pooling[0][0]']     \n",
      "                                                                                                  \n",
      " Min_block2_conv0 (Conv2D)      (None, 8, 8, 256)    295168      ['lambda_13[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 8, 8, 256)   1024        ['Max_block2_conv0[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 8, 8, 256)   1024        ['Min_block2_conv0[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.nn.relu_38 (TFOpLambda)     (None, 8, 8, 256)    0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 8, 8, 256)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " Max_block2_conv1 (Conv2D)      (None, 8, 8, 256)    590080      ['tf.nn.relu_38[0][0]']          \n",
      "                                                                                                  \n",
      " Min_block2_conv1 (Conv2D)      (None, 8, 8, 256)    590080      ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 8, 8, 256)   1024        ['Max_block2_conv1[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 8, 8, 256)   1024        ['Min_block2_conv1[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.nn.relu_39 (TFOpLambda)     (None, 8, 8, 256)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 8, 8, 256)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " Max_block2_conv2 (Conv2D)      (None, 8, 8, 256)    590080      ['tf.nn.relu_39[0][0]']          \n",
      "                                                                                                  \n",
      " Min_block2_conv2 (Conv2D)      (None, 8, 8, 256)    590080      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 8, 8, 256)   1024        ['Max_block2_conv2[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 8, 8, 256)   1024        ['Min_block2_conv2[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.nn.relu_40 (TFOpLambda)     (None, 8, 8, 256)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 8, 8, 256)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " Max_block2_pooling (MaxPooling  (None, 4, 4, 256)   0           ['tf.nn.relu_40[0][0]']          \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " lambda_14 (Lambda)             (None, 4, 4, 256)    0           ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " Max_block3_conv0 (Conv2D)      (None, 4, 4, 512)    1180160     ['Max_block2_pooling[0][0]']     \n",
      "                                                                                                  \n",
      " Min_block3_conv0 (Conv2D)      (None, 4, 4, 512)    1180160     ['lambda_14[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 4, 4, 512)   2048        ['Max_block3_conv0[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 4, 4, 512)   2048        ['Min_block3_conv0[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.nn.relu_41 (TFOpLambda)     (None, 4, 4, 512)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 4, 4, 512)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " Max_block3_conv1 (Conv2D)      (None, 4, 4, 512)    2359808     ['tf.nn.relu_41[0][0]']          \n",
      "                                                                                                  \n",
      " Min_block3_conv1 (Conv2D)      (None, 4, 4, 512)    2359808     ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 4, 4, 512)   2048        ['Max_block3_conv1[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 4, 4, 512)   2048        ['Min_block3_conv1[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.nn.relu_42 (TFOpLambda)     (None, 4, 4, 512)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 4, 4, 512)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " Max_block3_conv2 (Conv2D)      (None, 4, 4, 512)    2359808     ['tf.nn.relu_42[0][0]']          \n",
      "                                                                                                  \n",
      " Min_block3_conv2 (Conv2D)      (None, 4, 4, 512)    2359808     ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 4, 4, 512)   2048        ['Max_block3_conv2[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 4, 4, 512)   2048        ['Min_block3_conv2[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.nn.relu_43 (TFOpLambda)     (None, 4, 4, 512)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 4, 4, 512)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " Max_block3_pooling (MaxPooling  (None, 2, 2, 512)   0           ['tf.nn.relu_43[0][0]']          \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " lambda_15 (Lambda)             (None, 2, 2, 512)    0           ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)       (None, 2, 2, 1024)   0           ['Max_block3_pooling[0][0]',     \n",
      "                                                                  'lambda_15[0][0]']              \n",
      "                                                                                                  \n",
      " Dual_flatten (Flatten)         (None, 4096)         0           ['tf.concat_1[0][0]']            \n",
      "                                                                                                  \n",
      " Dual_fc1 (Dense)               (None, 512)          2097664     ['Dual_flatten[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 512)         2048        ['Dual_fc1[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 512)          0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " Dual_fc2 (Dense)               (None, 512)          262656      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 512)         2048        ['Dual_fc2[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 512)          0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 100)          51300       ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 17,707,748\n",
      "Trainable params: 17,694,948\n",
      "Non-trainable params: 12,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "D2_vgg_16 = D2_build_vgg()\n",
    "D2_vgg_16.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b90f2ce-37ff-4609-843e-2926cee82a7e",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8eb8f69f-9c4e-4ea9-a84b-47ad46626871",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 60\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c70a9578-617e-4fd4-925e-c404325df585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    }
   ],
   "source": [
    "wandbcallback_M=wandb.keras.WandbCallback(\"val_acc\", mode=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84780841-f0f7-4880-a127-2d905f3d0909",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 13:27:33.022836: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2499/2500 [============================>.] - ETA: 0s - loss: 4.2021 - acc: 0.0598 - top_k_categorical_accuracy: 0.2129"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 13:28:44.341307: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 81s 32ms/step - loss: 4.2020 - acc: 0.0598 - top_k_categorical_accuracy: 0.2130 - val_loss: 3.8161 - val_acc: 0.1019 - val_top_k_categorical_accuracy: 0.3241\n",
      "Epoch 2/60\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 3.6546 - acc: 0.1313 - top_k_categorical_accuracy: 0.3773"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 81s 33ms/step - loss: 3.6546 - acc: 0.1313 - top_k_categorical_accuracy: 0.3773 - val_loss: 3.3656 - val_acc: 0.1861 - val_top_k_categorical_accuracy: 0.4669\n",
      "Epoch 3/60\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 3.1739 - acc: 0.2124 - top_k_categorical_accuracy: 0.5076"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 80s 32ms/step - loss: 3.1739 - acc: 0.2124 - top_k_categorical_accuracy: 0.5076 - val_loss: 2.9087 - val_acc: 0.2635 - val_top_k_categorical_accuracy: 0.5720\n",
      "Epoch 4/60\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 2.7785 - acc: 0.2874 - top_k_categorical_accuracy: 0.6063"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 79s 32ms/step - loss: 2.7787 - acc: 0.2873 - top_k_categorical_accuracy: 0.6063 - val_loss: 2.6906 - val_acc: 0.3055 - val_top_k_categorical_accuracy: 0.6337\n",
      "Epoch 5/60\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 2.4600 - acc: 0.3467 - top_k_categorical_accuracy: 0.6807"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 80s 32ms/step - loss: 2.4601 - acc: 0.3467 - top_k_categorical_accuracy: 0.6807 - val_loss: 2.4205 - val_acc: 0.3576 - val_top_k_categorical_accuracy: 0.6863\n",
      "Epoch 6/60\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 2.2096 - acc: 0.4020 - top_k_categorical_accuracy: 0.7332"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 80s 32ms/step - loss: 2.2094 - acc: 0.4020 - top_k_categorical_accuracy: 0.7333 - val_loss: 2.5301 - val_acc: 0.3586 - val_top_k_categorical_accuracy: 0.6862\n",
      "Epoch 7/60\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 2.0061 - acc: 0.4493 - top_k_categorical_accuracy: 0.7762"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 80s 32ms/step - loss: 2.0063 - acc: 0.4493 - top_k_categorical_accuracy: 0.7762 - val_loss: 2.2898 - val_acc: 0.4054 - val_top_k_categorical_accuracy: 0.7289\n",
      "Epoch 8/60\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 1.8200 - acc: 0.4891 - top_k_categorical_accuracy: 0.8082"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 79s 32ms/step - loss: 1.8199 - acc: 0.4891 - top_k_categorical_accuracy: 0.8082 - val_loss: 2.1711 - val_acc: 0.4372 - val_top_k_categorical_accuracy: 0.7516\n",
      "Epoch 9/60\n",
      "2500/2500 [==============================] - 78s 31ms/step - loss: 1.6352 - acc: 0.5329 - top_k_categorical_accuracy: 0.8402 - val_loss: 2.1987 - val_acc: 0.4357 - val_top_k_categorical_accuracy: 0.7613\n",
      "Epoch 10/60\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 1.4548 - acc: 0.5761 - top_k_categorical_accuracy: 0.8708"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 81s 32ms/step - loss: 1.4548 - acc: 0.5761 - top_k_categorical_accuracy: 0.8708 - val_loss: 2.0944 - val_acc: 0.4609 - val_top_k_categorical_accuracy: 0.7791\n",
      "Epoch 11/60\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 1.2975 - acc: 0.6170 - top_k_categorical_accuracy: 0.8967"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 80s 32ms/step - loss: 1.2975 - acc: 0.6170 - top_k_categorical_accuracy: 0.8967 - val_loss: 2.0389 - val_acc: 0.4909 - val_top_k_categorical_accuracy: 0.7950\n",
      "Epoch 12/60\n",
      "2500/2500 [==============================] - 78s 31ms/step - loss: 1.1231 - acc: 0.6625 - top_k_categorical_accuracy: 0.9217 - val_loss: 2.1819 - val_acc: 0.4805 - val_top_k_categorical_accuracy: 0.7856\n",
      "Epoch 13/60\n",
      "2500/2500 [==============================] - 78s 31ms/step - loss: 0.9792 - acc: 0.6996 - top_k_categorical_accuracy: 0.9397 - val_loss: 2.2187 - val_acc: 0.4809 - val_top_k_categorical_accuracy: 0.7856\n",
      "Epoch 14/60\n",
      "2500/2500 [==============================] - 77s 31ms/step - loss: 0.8375 - acc: 0.7384 - top_k_categorical_accuracy: 0.9566 - val_loss: 2.2923 - val_acc: 0.4908 - val_top_k_categorical_accuracy: 0.7828\n",
      "Epoch 15/60\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 0.6999 - acc: 0.7773 - top_k_categorical_accuracy: 0.9696"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 81s 32ms/step - loss: 0.6999 - acc: 0.7773 - top_k_categorical_accuracy: 0.9696 - val_loss: 2.3912 - val_acc: 0.4920 - val_top_k_categorical_accuracy: 0.7869\n",
      "Epoch 16/60\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 0.6097 - acc: 0.8046 - top_k_categorical_accuracy: 0.9773"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 77s 31ms/step - loss: 0.6097 - acc: 0.8046 - top_k_categorical_accuracy: 0.9774 - val_loss: 2.4866 - val_acc: 0.4934 - val_top_k_categorical_accuracy: 0.7789\n",
      "Epoch 17/60\n",
      "2500/2500 [==============================] - 78s 31ms/step - loss: 0.5139 - acc: 0.8343 - top_k_categorical_accuracy: 0.9853 - val_loss: 2.6494 - val_acc: 0.4875 - val_top_k_categorical_accuracy: 0.7814\n",
      "Epoch 18/60\n",
      "2500/2500 [==============================] - 77s 31ms/step - loss: 0.4496 - acc: 0.8533 - top_k_categorical_accuracy: 0.9880 - val_loss: 2.8681 - val_acc: 0.4846 - val_top_k_categorical_accuracy: 0.7780\n",
      "Epoch 19/60\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 0.3935 - acc: 0.8701 - top_k_categorical_accuracy: 0.9918"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 79s 32ms/step - loss: 0.3934 - acc: 0.8702 - top_k_categorical_accuracy: 0.9919 - val_loss: 2.8068 - val_acc: 0.5027 - val_top_k_categorical_accuracy: 0.7926\n",
      "Epoch 20/60\n",
      "2500/2500 [==============================] - 77s 31ms/step - loss: 0.3460 - acc: 0.8854 - top_k_categorical_accuracy: 0.9934 - val_loss: 3.1025 - val_acc: 0.4836 - val_top_k_categorical_accuracy: 0.7771\n",
      "Epoch 21/60\n",
      "2500/2500 [==============================] - 77s 31ms/step - loss: 0.3169 - acc: 0.8946 - top_k_categorical_accuracy: 0.9942 - val_loss: 3.1638 - val_acc: 0.4873 - val_top_k_categorical_accuracy: 0.7769\n",
      "Epoch 22/60\n",
      "2500/2500 [==============================] - 77s 31ms/step - loss: 0.2903 - acc: 0.9051 - top_k_categorical_accuracy: 0.9953 - val_loss: 3.0995 - val_acc: 0.4980 - val_top_k_categorical_accuracy: 0.7805\n",
      "Epoch 23/60\n",
      "2500/2500 [==============================] - 77s 31ms/step - loss: 0.2644 - acc: 0.9126 - top_k_categorical_accuracy: 0.9963 - val_loss: 3.2808 - val_acc: 0.4832 - val_top_k_categorical_accuracy: 0.7690\n",
      "Epoch 24/60\n",
      "2500/2500 [==============================] - 78s 31ms/step - loss: 0.2437 - acc: 0.9194 - top_k_categorical_accuracy: 0.9970 - val_loss: 3.2350 - val_acc: 0.4972 - val_top_k_categorical_accuracy: 0.7826\n",
      "Epoch 25/60\n",
      "2500/2500 [==============================] - 78s 31ms/step - loss: 0.2223 - acc: 0.9269 - top_k_categorical_accuracy: 0.9974 - val_loss: 3.6635 - val_acc: 0.4727 - val_top_k_categorical_accuracy: 0.7541\n",
      "Epoch 26/60\n",
      "2500/2500 [==============================] - 77s 31ms/step - loss: 0.2167 - acc: 0.9293 - top_k_categorical_accuracy: 0.9976 - val_loss: 3.5223 - val_acc: 0.4859 - val_top_k_categorical_accuracy: 0.7667\n",
      "Epoch 27/60\n",
      "2500/2500 [==============================] - 77s 31ms/step - loss: 0.2071 - acc: 0.9320 - top_k_categorical_accuracy: 0.9975 - val_loss: 3.4510 - val_acc: 0.5003 - val_top_k_categorical_accuracy: 0.7769\n",
      "Epoch 28/60\n",
      "2500/2500 [==============================] - 77s 31ms/step - loss: 0.1848 - acc: 0.9382 - top_k_categorical_accuracy: 0.9979 - val_loss: 3.5387 - val_acc: 0.4916 - val_top_k_categorical_accuracy: 0.7735\n",
      "Epoch 29/60\n",
      "2500/2500 [==============================] - 77s 31ms/step - loss: 0.1901 - acc: 0.9397 - top_k_categorical_accuracy: 0.9977 - val_loss: 3.9205 - val_acc: 0.4747 - val_top_k_categorical_accuracy: 0.7512\n",
      "Epoch 30/60\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 0.1666 - acc: 0.9452 - top_k_categorical_accuracy: 0.9984"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 80s 32ms/step - loss: 0.1668 - acc: 0.9452 - top_k_categorical_accuracy: 0.9985 - val_loss: 3.5472 - val_acc: 0.5059 - val_top_k_categorical_accuracy: 0.7836\n",
      "Epoch 31/60\n",
      "2500/2500 [==============================] - 77s 31ms/step - loss: 0.1724 - acc: 0.9448 - top_k_categorical_accuracy: 0.9979 - val_loss: 3.7215 - val_acc: 0.4862 - val_top_k_categorical_accuracy: 0.7690\n",
      "Epoch 32/60\n",
      "2500/2500 [==============================] - 77s 31ms/step - loss: 0.1556 - acc: 0.9497 - top_k_categorical_accuracy: 0.9986 - val_loss: 3.7019 - val_acc: 0.4975 - val_top_k_categorical_accuracy: 0.7766\n",
      "Epoch 33/60\n",
      "2500/2500 [==============================] - 78s 31ms/step - loss: 0.1455 - acc: 0.9530 - top_k_categorical_accuracy: 0.9986 - val_loss: 3.6933 - val_acc: 0.5045 - val_top_k_categorical_accuracy: 0.7830\n",
      "Epoch 34/60\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 0.1500 - acc: 0.9513 - top_k_categorical_accuracy: 0.9985"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 80s 32ms/step - loss: 0.1500 - acc: 0.9513 - top_k_categorical_accuracy: 0.9985 - val_loss: 3.6008 - val_acc: 0.5131 - val_top_k_categorical_accuracy: 0.7904\n",
      "Epoch 35/60\n",
      "2500/2500 [==============================] - 77s 31ms/step - loss: 0.1348 - acc: 0.9560 - top_k_categorical_accuracy: 0.9989 - val_loss: 3.6406 - val_acc: 0.5119 - val_top_k_categorical_accuracy: 0.7892\n",
      "Epoch 36/60\n",
      "2500/2500 [==============================] - 78s 31ms/step - loss: 0.1337 - acc: 0.9565 - top_k_categorical_accuracy: 0.9987 - val_loss: 3.7145 - val_acc: 0.5055 - val_top_k_categorical_accuracy: 0.7862\n",
      "Epoch 37/60\n",
      "2500/2500 [==============================] - 77s 31ms/step - loss: 0.1285 - acc: 0.9590 - top_k_categorical_accuracy: 0.9988 - val_loss: 3.8037 - val_acc: 0.5005 - val_top_k_categorical_accuracy: 0.7827\n",
      "Epoch 38/60\n",
      "2500/2500 [==============================] - 77s 31ms/step - loss: 0.1299 - acc: 0.9581 - top_k_categorical_accuracy: 0.9989 - val_loss: 3.8824 - val_acc: 0.4986 - val_top_k_categorical_accuracy: 0.7789\n",
      "Epoch 39/60\n",
      "2500/2500 [==============================] - 77s 31ms/step - loss: 0.1223 - acc: 0.9607 - top_k_categorical_accuracy: 0.9989 - val_loss: 3.8698 - val_acc: 0.4932 - val_top_k_categorical_accuracy: 0.7749\n",
      "Epoch 40/60\n",
      "2500/2500 [==============================] - 77s 31ms/step - loss: 0.1208 - acc: 0.9607 - top_k_categorical_accuracy: 0.9987 - val_loss: 3.7986 - val_acc: 0.4960 - val_top_k_categorical_accuracy: 0.7735\n",
      "Epoch 41/60\n",
      "2500/2500 [==============================] - 76s 30ms/step - loss: 0.1083 - acc: 0.9655 - top_k_categorical_accuracy: 0.9993 - val_loss: 4.0669 - val_acc: 0.4869 - val_top_k_categorical_accuracy: 0.7657\n",
      "Epoch 42/60\n",
      "2500/2500 [==============================] - 77s 31ms/step - loss: 0.1146 - acc: 0.9630 - top_k_categorical_accuracy: 0.9987 - val_loss: 3.8868 - val_acc: 0.4986 - val_top_k_categorical_accuracy: 0.7752\n",
      "Epoch 43/60\n",
      "2500/2500 [==============================] - 78s 31ms/step - loss: 0.1016 - acc: 0.9669 - top_k_categorical_accuracy: 0.9994 - val_loss: 4.2527 - val_acc: 0.4902 - val_top_k_categorical_accuracy: 0.7627\n",
      "Epoch 44/60\n",
      "2500/2500 [==============================] - 78s 31ms/step - loss: 0.1080 - acc: 0.9655 - top_k_categorical_accuracy: 0.9991 - val_loss: 3.9325 - val_acc: 0.4987 - val_top_k_categorical_accuracy: 0.7751\n",
      "Epoch 45/60\n",
      "2500/2500 [==============================] - 78s 31ms/step - loss: 0.0998 - acc: 0.9668 - top_k_categorical_accuracy: 0.9992 - val_loss: 3.9844 - val_acc: 0.5014 - val_top_k_categorical_accuracy: 0.7680\n",
      "Epoch 46/60\n",
      "2500/2500 [==============================] - 78s 31ms/step - loss: 0.1018 - acc: 0.9668 - top_k_categorical_accuracy: 0.9992 - val_loss: 4.1181 - val_acc: 0.5022 - val_top_k_categorical_accuracy: 0.7659\n",
      "Epoch 47/60\n",
      "2500/2500 [==============================] - 78s 31ms/step - loss: 0.0948 - acc: 0.9702 - top_k_categorical_accuracy: 0.9992 - val_loss: 3.9739 - val_acc: 0.5025 - val_top_k_categorical_accuracy: 0.7706\n",
      "Epoch 48/60\n",
      "2500/2500 [==============================] - 78s 31ms/step - loss: 0.0969 - acc: 0.9686 - top_k_categorical_accuracy: 0.9991 - val_loss: 3.9086 - val_acc: 0.5095 - val_top_k_categorical_accuracy: 0.7759\n",
      "Epoch 49/60\n",
      "2500/2500 [==============================] - 78s 31ms/step - loss: 0.0906 - acc: 0.9717 - top_k_categorical_accuracy: 0.9991 - val_loss: 4.0588 - val_acc: 0.4994 - val_top_k_categorical_accuracy: 0.7659\n",
      "Epoch 50/60\n",
      "2500/2500 [==============================] - 80s 32ms/step - loss: 0.0878 - acc: 0.9719 - top_k_categorical_accuracy: 0.9990 - val_loss: 4.2045 - val_acc: 0.4917 - val_top_k_categorical_accuracy: 0.7607\n",
      "Epoch 51/60\n",
      "2500/2500 [==============================] - 78s 31ms/step - loss: 0.0842 - acc: 0.9729 - top_k_categorical_accuracy: 0.9992 - val_loss: 4.1319 - val_acc: 0.5027 - val_top_k_categorical_accuracy: 0.7635\n",
      "Epoch 52/60\n",
      "2500/2500 [==============================] - 78s 31ms/step - loss: 0.0886 - acc: 0.9715 - top_k_categorical_accuracy: 0.9992 - val_loss: 4.0968 - val_acc: 0.5010 - val_top_k_categorical_accuracy: 0.7733\n",
      "Epoch 53/60\n",
      "2500/2500 [==============================] - 78s 31ms/step - loss: 0.0844 - acc: 0.9732 - top_k_categorical_accuracy: 0.9996 - val_loss: 4.1511 - val_acc: 0.4974 - val_top_k_categorical_accuracy: 0.7674\n",
      "Epoch 54/60\n",
      "2500/2500 [==============================] - 78s 31ms/step - loss: 0.0812 - acc: 0.9741 - top_k_categorical_accuracy: 0.9995 - val_loss: 4.0408 - val_acc: 0.5027 - val_top_k_categorical_accuracy: 0.7734\n",
      "Epoch 55/60\n",
      "2500/2500 [==============================] - 78s 31ms/step - loss: 0.0792 - acc: 0.9746 - top_k_categorical_accuracy: 0.9995 - val_loss: 4.1255 - val_acc: 0.5053 - val_top_k_categorical_accuracy: 0.7718\n",
      "Epoch 56/60\n",
      "2500/2500 [==============================] - 78s 31ms/step - loss: 0.0775 - acc: 0.9755 - top_k_categorical_accuracy: 0.9995 - val_loss: 4.1257 - val_acc: 0.4954 - val_top_k_categorical_accuracy: 0.7695\n",
      "Epoch 57/60\n",
      "2500/2500 [==============================] - 78s 31ms/step - loss: 0.0770 - acc: 0.9751 - top_k_categorical_accuracy: 0.9994 - val_loss: 4.1291 - val_acc: 0.5025 - val_top_k_categorical_accuracy: 0.7732\n",
      "Epoch 58/60\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 0.0746 - acc: 0.9759 - top_k_categorical_accuracy: 0.9995"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221012_132512-3v9e9kz2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 80s 32ms/step - loss: 0.0746 - acc: 0.9759 - top_k_categorical_accuracy: 0.9995 - val_loss: 3.9978 - val_acc: 0.5153 - val_top_k_categorical_accuracy: 0.7748\n",
      "Epoch 59/60\n",
      "2500/2500 [==============================] - 77s 31ms/step - loss: 0.0708 - acc: 0.9781 - top_k_categorical_accuracy: 0.9994 - val_loss: 4.0581 - val_acc: 0.5109 - val_top_k_categorical_accuracy: 0.7764\n",
      "Epoch 60/60\n",
      "2500/2500 [==============================] - 77s 31ms/step - loss: 0.0712 - acc: 0.9769 - top_k_categorical_accuracy: 0.9997 - val_loss: 4.2068 - val_acc: 0.5057 - val_top_k_categorical_accuracy: 0.7673\n"
     ]
    }
   ],
   "source": [
    "# Max\n",
    "vgg_16.compile(loss=categorical_crossentropy, \n",
    "              optimizer=Adam(learning_rate=0.001), \n",
    "              metrics=['acc','top_k_categorical_accuracy'])\n",
    "\n",
    "history = vgg_16.fit(X_train,  # 학습할 데이터\n",
    "                    y_train,  # 학습할 레이블\n",
    "                    epochs=EPOCHS,  # 전체 학습할 횟수\n",
    "                    batch_size=BATCH_SIZE,  # 배치 사이즈\n",
    "                    use_multiprocessing=True,\n",
    "                    validation_data=(X_valid, y_valid), # 검증 데이터로 확인\n",
    "                    callbacks=[wandbcallback_M]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903e8374-2303-4464-9560-119d166824d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 12:37:49.311430: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_shape:  (16, 32, 32, 64)\n",
      "B, w, h, C:  16 32 32 64\n",
      "x_shape:  (16, 16, 16, 128)\n",
      "B, w, h, C:  16 16 16 128\n",
      "x_shape:  (16, 8, 8, 256)\n",
      "B, w, h, C:  16 8 8 256\n",
      "x_shape:  (16, 4, 4, 512)\n",
      "B, w, h, C:  16 4 4 512\n",
      "x_shape:  (16, 32, 32, 64)\n",
      "B, w, h, C:  16 32 32 64\n",
      "x_shape:  (16, 16, 16, 128)\n",
      "B, w, h, C:  16 16 16 128\n",
      "x_shape:  (16, 8, 8, 256)\n",
      "B, w, h, C:  16 8 8 256\n",
      "x_shape:  (16, 4, 4, 512)\n",
      "B, w, h, C:  16 4 4 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 12:37:49.981052: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - ETA: 0s - loss: 4.1820 - acc: 0.0646 - top_k_categorical_accuracy: 0.2260x_shape:  (16, 32, 32, 64)\n",
      "B, w, h, C:  16 32 32 64\n",
      "x_shape:  (16, 16, 16, 128)\n",
      "B, w, h, C:  16 16 16 128\n",
      "x_shape:  (16, 8, 8, 256)\n",
      "B, w, h, C:  16 8 8 256\n",
      "x_shape:  (16, 4, 4, 512)\n",
      "B, w, h, C:  16 4 4 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 12:40:14.773915: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 161s 64ms/step - loss: 4.1820 - acc: 0.0646 - top_k_categorical_accuracy: 0.2260 - val_loss: 7.2977 - val_acc: 0.0299 - val_top_k_categorical_accuracy: 0.1260\n",
      "Epoch 2/60\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 3.5494 - acc: 0.1525 - top_k_categorical_accuracy: 0.4083x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 211s 85ms/step - loss: 3.5494 - acc: 0.1525 - top_k_categorical_accuracy: 0.4083 - val_loss: 3.7783 - val_acc: 0.1681 - val_top_k_categorical_accuracy: 0.4382\n",
      "Epoch 3/60\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 3.0552 - acc: 0.2311 - top_k_categorical_accuracy: 0.5342x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 159s 64ms/step - loss: 3.0552 - acc: 0.2311 - top_k_categorical_accuracy: 0.5342 - val_loss: 3.2112 - val_acc: 0.2332 - val_top_k_categorical_accuracy: 0.5201\n",
      "Epoch 4/60\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 2.6623 - acc: 0.3082 - top_k_categorical_accuracy: 0.6356x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 1100s 440ms/step - loss: 2.6623 - acc: 0.3082 - top_k_categorical_accuracy: 0.6356 - val_loss: 2.7137 - val_acc: 0.3000 - val_top_k_categorical_accuracy: 0.6293\n",
      "Epoch 5/60\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 2.3767 - acc: 0.3659 - top_k_categorical_accuracy: 0.6984x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 163s 65ms/step - loss: 2.3767 - acc: 0.3659 - top_k_categorical_accuracy: 0.6984 - val_loss: 2.4560 - val_acc: 0.3617 - val_top_k_categorical_accuracy: 0.6849\n",
      "Epoch 6/60\n",
      "2500/2500 [==============================] - 212s 85ms/step - loss: 2.1431 - acc: 0.4157 - top_k_categorical_accuracy: 0.7483 - val_loss: 2.6073 - val_acc: 0.3433 - val_top_k_categorical_accuracy: 0.6540\n",
      "Epoch 7/60\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 1.9308 - acc: 0.4641 - top_k_categorical_accuracy: 0.7876x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 1196s 478ms/step - loss: 1.9308 - acc: 0.4641 - top_k_categorical_accuracy: 0.7876 - val_loss: 2.3407 - val_acc: 0.3924 - val_top_k_categorical_accuracy: 0.7253\n",
      "Epoch 8/60\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 1.7452 - acc: 0.5075 - top_k_categorical_accuracy: 0.8206x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 160s 64ms/step - loss: 1.7452 - acc: 0.5075 - top_k_categorical_accuracy: 0.8206 - val_loss: 2.1018 - val_acc: 0.4443 - val_top_k_categorical_accuracy: 0.7577\n",
      "Epoch 9/60\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 1.5527 - acc: 0.5532 - top_k_categorical_accuracy: 0.8584x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 160s 64ms/step - loss: 1.5527 - acc: 0.5532 - top_k_categorical_accuracy: 0.8584 - val_loss: 2.1200 - val_acc: 0.4569 - val_top_k_categorical_accuracy: 0.7725\n",
      "Epoch 10/60\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 1.3843 - acc: 0.5951 - top_k_categorical_accuracy: 0.8837x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 168s 67ms/step - loss: 1.3843 - acc: 0.5951 - top_k_categorical_accuracy: 0.8837 - val_loss: 2.0975 - val_acc: 0.4679 - val_top_k_categorical_accuracy: 0.7751\n",
      "Epoch 11/60\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 1.2091 - acc: 0.6401 - top_k_categorical_accuracy: 0.9095x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 2040s 816ms/step - loss: 1.2091 - acc: 0.6401 - top_k_categorical_accuracy: 0.9095 - val_loss: 2.0956 - val_acc: 0.4759 - val_top_k_categorical_accuracy: 0.7872\n",
      "Epoch 12/60\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 1.0545 - acc: 0.6779 - top_k_categorical_accuracy: 0.9299x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 161s 64ms/step - loss: 1.0545 - acc: 0.6779 - top_k_categorical_accuracy: 0.9299 - val_loss: 2.1387 - val_acc: 0.4909 - val_top_k_categorical_accuracy: 0.7878\n",
      "Epoch 13/60\n",
      "2500/2500 [==============================] - 158s 63ms/step - loss: 0.9016 - acc: 0.7233 - top_k_categorical_accuracy: 0.9488 - val_loss: 2.4607 - val_acc: 0.4637 - val_top_k_categorical_accuracy: 0.7678\n",
      "Epoch 14/60\n",
      "2500/2500 [==============================] - 158s 63ms/step - loss: 0.7582 - acc: 0.7612 - top_k_categorical_accuracy: 0.9646 - val_loss: 2.4556 - val_acc: 0.4672 - val_top_k_categorical_accuracy: 0.7713\n",
      "Epoch 15/60\n",
      "2500/2500 [==============================] - 166s 66ms/step - loss: 0.6407 - acc: 0.7960 - top_k_categorical_accuracy: 0.9750 - val_loss: 2.4633 - val_acc: 0.4900 - val_top_k_categorical_accuracy: 0.7806\n",
      "Epoch 16/60\n",
      "2500/2500 [==============================] - 169s 68ms/step - loss: 0.5437 - acc: 0.8252 - top_k_categorical_accuracy: 0.9825 - val_loss: 2.7183 - val_acc: 0.4832 - val_top_k_categorical_accuracy: 0.7705\n",
      "Epoch 17/60\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 0.4691 - acc: 0.8453 - top_k_categorical_accuracy: 0.9874x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 174s 70ms/step - loss: 0.4691 - acc: 0.8453 - top_k_categorical_accuracy: 0.9874 - val_loss: 2.5893 - val_acc: 0.5006 - val_top_k_categorical_accuracy: 0.7895\n",
      "Epoch 18/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.4027 - acc: 0.8704 - top_k_categorical_accuracy: 0.9909 - val_loss: 3.1126 - val_acc: 0.4753 - val_top_k_categorical_accuracy: 0.7614\n",
      "Epoch 19/60\n",
      "2500/2500 [==============================] - 179s 72ms/step - loss: 0.3639 - acc: 0.8786 - top_k_categorical_accuracy: 0.9931 - val_loss: 3.0044 - val_acc: 0.4940 - val_top_k_categorical_accuracy: 0.7749\n",
      "Epoch 20/60\n",
      "2500/2500 [==============================] - 186s 75ms/step - loss: 0.3261 - acc: 0.8935 - top_k_categorical_accuracy: 0.9940 - val_loss: 3.3836 - val_acc: 0.4781 - val_top_k_categorical_accuracy: 0.7597\n",
      "Epoch 21/60\n",
      "2500/2500 [==============================] - 188s 75ms/step - loss: 0.2958 - acc: 0.9038 - top_k_categorical_accuracy: 0.9951 - val_loss: 3.1566 - val_acc: 0.4965 - val_top_k_categorical_accuracy: 0.7746\n",
      "Epoch 22/60\n",
      "2500/2500 [==============================] - 188s 75ms/step - loss: 0.2759 - acc: 0.9110 - top_k_categorical_accuracy: 0.9951 - val_loss: 3.3209 - val_acc: 0.4897 - val_top_k_categorical_accuracy: 0.7774\n",
      "Epoch 23/60\n",
      "2500/2500 [==============================] - 186s 74ms/step - loss: 0.2494 - acc: 0.9182 - top_k_categorical_accuracy: 0.9968 - val_loss: 3.2269 - val_acc: 0.4977 - val_top_k_categorical_accuracy: 0.7777\n",
      "Epoch 24/60\n",
      "2500/2500 [==============================] - 186s 75ms/step - loss: 0.2436 - acc: 0.9207 - top_k_categorical_accuracy: 0.9962 - val_loss: 3.4317 - val_acc: 0.4816 - val_top_k_categorical_accuracy: 0.7680\n",
      "Epoch 25/60\n",
      "2500/2500 [==============================] - 188s 75ms/step - loss: 0.2224 - acc: 0.9279 - top_k_categorical_accuracy: 0.9972 - val_loss: 3.4563 - val_acc: 0.4872 - val_top_k_categorical_accuracy: 0.7724\n",
      "Epoch 26/60\n",
      "2500/2500 [==============================] - 187s 75ms/step - loss: 0.2033 - acc: 0.9339 - top_k_categorical_accuracy: 0.9972 - val_loss: 3.5252 - val_acc: 0.4925 - val_top_k_categorical_accuracy: 0.7699\n",
      "Epoch 27/60\n",
      "2500/2500 [==============================] - 188s 75ms/step - loss: 0.1942 - acc: 0.9371 - top_k_categorical_accuracy: 0.9978 - val_loss: 3.5244 - val_acc: 0.4897 - val_top_k_categorical_accuracy: 0.7700\n",
      "Epoch 28/60\n",
      "2500/2500 [==============================] - 190s 76ms/step - loss: 0.1727 - acc: 0.9433 - top_k_categorical_accuracy: 0.9984 - val_loss: 3.5874 - val_acc: 0.4868 - val_top_k_categorical_accuracy: 0.7682\n",
      "Epoch 29/60\n",
      "2500/2500 [==============================] - 192s 77ms/step - loss: 0.1792 - acc: 0.9409 - top_k_categorical_accuracy: 0.9983 - val_loss: 3.7075 - val_acc: 0.4871 - val_top_k_categorical_accuracy: 0.7676\n",
      "Epoch 30/60\n",
      "2500/2500 [==============================] - 195s 78ms/step - loss: 0.1711 - acc: 0.9449 - top_k_categorical_accuracy: 0.9983 - val_loss: 3.8842 - val_acc: 0.4834 - val_top_k_categorical_accuracy: 0.7602\n",
      "Epoch 31/60\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 0.1641 - acc: 0.9462 - top_k_categorical_accuracy: 0.9985x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n",
      "x_shape:  (None, 32, 32, 64)\n",
      "B, w, h, C:  None 32 32 64\n",
      "x_shape:  (None, 16, 16, 128)\n",
      "B, w, h, C:  None 16 16 128\n",
      "x_shape:  (None, 8, 8, 256)\n",
      "B, w, h, C:  None 8 8 256\n",
      "x_shape:  (None, 4, 4, 512)\n",
      "B, w, h, C:  None 4 4 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/dip_phd/PHD/wandb/run-20221013_123617-3r4niog2/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 193s 77ms/step - loss: 0.1641 - acc: 0.9462 - top_k_categorical_accuracy: 0.9985 - val_loss: 3.5740 - val_acc: 0.5022 - val_top_k_categorical_accuracy: 0.7767\n",
      "Epoch 32/60\n",
      "2500/2500 [==============================] - 196s 78ms/step - loss: 0.1463 - acc: 0.9525 - top_k_categorical_accuracy: 0.9985 - val_loss: 3.9945 - val_acc: 0.4867 - val_top_k_categorical_accuracy: 0.7649\n",
      "Epoch 33/60\n",
      "2500/2500 [==============================] - 187s 75ms/step - loss: 0.1519 - acc: 0.9507 - top_k_categorical_accuracy: 0.9987 - val_loss: 3.7737 - val_acc: 0.4843 - val_top_k_categorical_accuracy: 0.7674\n",
      "Epoch 34/60\n",
      "2500/2500 [==============================] - 190s 76ms/step - loss: 0.1477 - acc: 0.9521 - top_k_categorical_accuracy: 0.9986 - val_loss: 3.7237 - val_acc: 0.4957 - val_top_k_categorical_accuracy: 0.7755\n",
      "Epoch 35/60\n",
      "1806/2500 [====================>.........] - ETA: 48s - loss: 0.1255 - acc: 0.9599 - top_k_categorical_accuracy: 0.9987"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 264s 106ms/step - loss: 0.1309 - acc: 0.9579 - top_k_categorical_accuracy: 0.9988 - val_loss: 3.7205 - val_acc: 0.5015 - val_top_k_categorical_accuracy: 0.7724\n",
      "Epoch 36/60\n",
      "1448/2500 [================>.............] - ETA: 1:01 - loss: 0.1261 - acc: 0.9592 - top_k_categorical_accuracy: 0.9987"
     ]
    }
   ],
   "source": [
    "# Min\n",
    "M_vgg_16.compile(loss=categorical_crossentropy, \n",
    "              optimizer=Adam(learning_rate=0.001), \n",
    "              metrics=['acc','top_k_categorical_accuracy'])\n",
    "\n",
    "history = M_vgg_16.fit(X_train,  # 학습할 데이터\n",
    "                    y_train,  # 학습할 레이블\n",
    "                    epochs=EPOCHS,  # 전체 학습할 횟수\n",
    "                    batch_size=BATCH_SIZE,  # 배치 사이즈\n",
    "                    use_multiprocessing=True,\n",
    "                    validation_data=(X_valid, y_valid), # 검증 데이터로 확인\n",
    "                    callbacks=[wandbcallback_M]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90f9723b-c121-429a-983b-e57e3be61466",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "2500/2500 [==============================] - 200s 71ms/step - loss: 4.1989 - acc: 0.0551 - top_k_categorical_accuracy: 0.2044 - val_loss: 3.9461 - val_acc: 0.0825 - val_top_k_categorical_accuracy: 0.2761 - _timestamp: 1664964363.0000 - _runtime: 234.0000\n",
      "Epoch 2/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 3.8876 - acc: 0.0952 - top_k_categorical_accuracy: 0.2996 - val_loss: 3.9771 - val_acc: 0.0888 - val_top_k_categorical_accuracy: 0.2740 - _timestamp: 1664964535.0000 - _runtime: 406.0000\n",
      "Epoch 3/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 3.7274 - acc: 0.1185 - top_k_categorical_accuracy: 0.3508 - val_loss: 3.7316 - val_acc: 0.1197 - val_top_k_categorical_accuracy: 0.3618 - _timestamp: 1664964708.0000 - _runtime: 579.0000\n",
      "Epoch 4/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 3.5755 - acc: 0.1464 - top_k_categorical_accuracy: 0.3957 - val_loss: 3.6377 - val_acc: 0.1445 - val_top_k_categorical_accuracy: 0.3868 - _timestamp: 1664964881.0000 - _runtime: 752.0000\n",
      "Epoch 5/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 3.4296 - acc: 0.1709 - top_k_categorical_accuracy: 0.4393 - val_loss: 4.0713 - val_acc: 0.1822 - val_top_k_categorical_accuracy: 0.4480 - _timestamp: 1664965054.0000 - _runtime: 925.0000\n",
      "Epoch 6/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 3.2931 - acc: 0.1931 - top_k_categorical_accuracy: 0.4754 - val_loss: 3.6594 - val_acc: 0.1963 - val_top_k_categorical_accuracy: 0.4771 - _timestamp: 1664965228.0000 - _runtime: 1099.0000\n",
      "Epoch 7/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 3.2003 - acc: 0.2125 - top_k_categorical_accuracy: 0.4983 - val_loss: 3.3422 - val_acc: 0.1974 - val_top_k_categorical_accuracy: 0.4779 - _timestamp: 1664965401.0000 - _runtime: 1272.0000\n",
      "Epoch 8/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 3.0984 - acc: 0.2300 - top_k_categorical_accuracy: 0.5229 - val_loss: 6.3918 - val_acc: 0.0764 - val_top_k_categorical_accuracy: 0.2468 - _timestamp: 1664965574.0000 - _runtime: 1445.0000\n",
      "Epoch 9/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 3.0248 - acc: 0.2424 - top_k_categorical_accuracy: 0.5415 - val_loss: 4.3802 - val_acc: 0.1953 - val_top_k_categorical_accuracy: 0.4740 - _timestamp: 1664965746.0000 - _runtime: 1617.0000\n",
      "Epoch 10/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 2.9456 - acc: 0.2599 - top_k_categorical_accuracy: 0.5623 - val_loss: 30.6882 - val_acc: 0.2343 - val_top_k_categorical_accuracy: 0.5353 - _timestamp: 1664965918.0000 - _runtime: 1789.0000\n",
      "Epoch 11/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 2.8022 - acc: 0.2876 - top_k_categorical_accuracy: 0.5939 - val_loss: 109.1057 - val_acc: 0.2560 - val_top_k_categorical_accuracy: 0.5503 - _timestamp: 1664966090.0000 - _runtime: 1961.0000\n",
      "Epoch 12/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 2.7674 - acc: 0.2953 - top_k_categorical_accuracy: 0.6051 - val_loss: 4.1896 - val_acc: 0.2744 - val_top_k_categorical_accuracy: 0.5688 - _timestamp: 1664966263.0000 - _runtime: 2134.0000\n",
      "Epoch 13/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 2.7109 - acc: 0.3079 - top_k_categorical_accuracy: 0.6158 - val_loss: 15.5163 - val_acc: 0.2660 - val_top_k_categorical_accuracy: 0.5658 - _timestamp: 1664966436.0000 - _runtime: 2307.0000\n",
      "Epoch 14/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 2.6049 - acc: 0.3291 - top_k_categorical_accuracy: 0.6420 - val_loss: 46.6698 - val_acc: 0.2620 - val_top_k_categorical_accuracy: 0.5584 - _timestamp: 1664966608.0000 - _runtime: 2479.0000\n",
      "Epoch 15/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 2.5242 - acc: 0.3472 - top_k_categorical_accuracy: 0.6576 - val_loss: 184.1409 - val_acc: 0.3131 - val_top_k_categorical_accuracy: 0.6219 - _timestamp: 1664966780.0000 - _runtime: 2651.0000\n",
      "Epoch 16/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 2.4398 - acc: 0.3599 - top_k_categorical_accuracy: 0.6758 - val_loss: 18.2862 - val_acc: 0.3002 - val_top_k_categorical_accuracy: 0.6018 - _timestamp: 1664966953.0000 - _runtime: 2824.0000\n",
      "Epoch 17/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 2.3800 - acc: 0.3728 - top_k_categorical_accuracy: 0.6904 - val_loss: 117.2729 - val_acc: 0.2974 - val_top_k_categorical_accuracy: 0.6158 - _timestamp: 1664967126.0000 - _runtime: 2997.0000\n",
      "Epoch 18/60\n",
      "2500/2500 [==============================] - 174s 69ms/step - loss: 2.3503 - acc: 0.3798 - top_k_categorical_accuracy: 0.6977 - val_loss: 10.3291 - val_acc: 0.3250 - val_top_k_categorical_accuracy: 0.6366 - _timestamp: 1664967298.0000 - _runtime: 3169.0000\n",
      "Epoch 19/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 2.1982 - acc: 0.4090 - top_k_categorical_accuracy: 0.7288 - val_loss: 65.9273 - val_acc: 0.2892 - val_top_k_categorical_accuracy: 0.5941 - _timestamp: 1664967472.0000 - _runtime: 3343.0000\n",
      "Epoch 20/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 2.0930 - acc: 0.4326 - top_k_categorical_accuracy: 0.7512 - val_loss: 6.0593 - val_acc: 0.3351 - val_top_k_categorical_accuracy: 0.6384 - _timestamp: 1664967644.0000 - _runtime: 3515.0000\n",
      "Epoch 21/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 2.0592 - acc: 0.4401 - top_k_categorical_accuracy: 0.7581 - val_loss: 133.6182 - val_acc: 0.3168 - val_top_k_categorical_accuracy: 0.6292 - _timestamp: 1664967817.0000 - _runtime: 3688.0000\n",
      "Epoch 22/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 1.9396 - acc: 0.4672 - top_k_categorical_accuracy: 0.7800 - val_loss: 34.6163 - val_acc: 0.3335 - val_top_k_categorical_accuracy: 0.6385 - _timestamp: 1664967990.0000 - _runtime: 3861.0000\n",
      "Epoch 23/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 1.8553 - acc: 0.4828 - top_k_categorical_accuracy: 0.7948 - val_loss: 148.7079 - val_acc: 0.3439 - val_top_k_categorical_accuracy: 0.6483 - _timestamp: 1664968163.0000 - _runtime: 4034.0000\n",
      "Epoch 24/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 1.8470 - acc: 0.4878 - top_k_categorical_accuracy: 0.7972 - val_loss: 14.2937 - val_acc: 0.3386 - val_top_k_categorical_accuracy: 0.6458 - _timestamp: 1664968336.0000 - _runtime: 4207.0000\n",
      "Epoch 25/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 1.6681 - acc: 0.5298 - top_k_categorical_accuracy: 0.8303 - val_loss: 28.5239 - val_acc: 0.3349 - val_top_k_categorical_accuracy: 0.6387 - _timestamp: 1664968509.0000 - _runtime: 4380.0000\n",
      "Epoch 26/60\n",
      "2500/2500 [==============================] - 174s 69ms/step - loss: 1.5515 - acc: 0.5565 - top_k_categorical_accuracy: 0.8507 - val_loss: 12.4694 - val_acc: 0.3440 - val_top_k_categorical_accuracy: 0.6478 - _timestamp: 1664968682.0000 - _runtime: 4553.0000\n",
      "Epoch 27/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 1.5069 - acc: 0.5687 - top_k_categorical_accuracy: 0.8585 - val_loss: 11.3168 - val_acc: 0.3391 - val_top_k_categorical_accuracy: 0.6456 - _timestamp: 1664968855.0000 - _runtime: 4726.0000\n",
      "Epoch 28/60\n",
      "2500/2500 [==============================] - 174s 70ms/step - loss: 1.3983 - acc: 0.5940 - top_k_categorical_accuracy: 0.8767 - val_loss: 77.0245 - val_acc: 0.3521 - val_top_k_categorical_accuracy: 0.6564 - _timestamp: 1664969028.0000 - _runtime: 4899.0000\n",
      "Epoch 29/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 1.2557 - acc: 0.6316 - top_k_categorical_accuracy: 0.8969 - val_loss: 9.8184 - val_acc: 0.3459 - val_top_k_categorical_accuracy: 0.6445 - _timestamp: 1664969202.0000 - _runtime: 5073.0000\n",
      "Epoch 30/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 1.1604 - acc: 0.6554 - top_k_categorical_accuracy: 0.9118 - val_loss: 1185.2198 - val_acc: 0.3431 - val_top_k_categorical_accuracy: 0.6423 - _timestamp: 1664969374.0000 - _runtime: 5245.0000\n",
      "Epoch 31/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 1.0422 - acc: 0.6852 - top_k_categorical_accuracy: 0.9284 - val_loss: 32.5059 - val_acc: 0.3353 - val_top_k_categorical_accuracy: 0.6301 - _timestamp: 1664969547.0000 - _runtime: 5418.0000\n",
      "Epoch 32/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 0.9525 - acc: 0.7088 - top_k_categorical_accuracy: 0.9411 - val_loss: 18.0036 - val_acc: 0.3401 - val_top_k_categorical_accuracy: 0.6376 - _timestamp: 1664969720.0000 - _runtime: 5591.0000\n",
      "Epoch 33/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.8594 - acc: 0.7365 - top_k_categorical_accuracy: 0.9514 - val_loss: 6.6526 - val_acc: 0.3122 - val_top_k_categorical_accuracy: 0.6093 - _timestamp: 1664969892.0000 - _runtime: 5763.0000\n",
      "Epoch 34/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.7925 - acc: 0.7565 - top_k_categorical_accuracy: 0.9599 - val_loss: 5.7026 - val_acc: 0.3412 - val_top_k_categorical_accuracy: 0.6336 - _timestamp: 1664970065.0000 - _runtime: 5936.0000\n",
      "Epoch 35/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.7064 - acc: 0.7797 - top_k_categorical_accuracy: 0.9678 - val_loss: 102.0133 - val_acc: 0.3170 - val_top_k_categorical_accuracy: 0.6112 - _timestamp: 1664970238.0000 - _runtime: 6109.0000\n",
      "Epoch 36/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.7027 - acc: 0.7810 - top_k_categorical_accuracy: 0.9685 - val_loss: 58.3885 - val_acc: 0.3335 - val_top_k_categorical_accuracy: 0.6319 - _timestamp: 1664970411.0000 - _runtime: 6282.0000\n",
      "Epoch 37/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 0.6442 - acc: 0.8011 - top_k_categorical_accuracy: 0.9725 - val_loss: 7.4465 - val_acc: 0.3451 - val_top_k_categorical_accuracy: 0.6358 - _timestamp: 1664970583.0000 - _runtime: 6454.0000\n",
      "Epoch 38/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 0.6043 - acc: 0.8098 - top_k_categorical_accuracy: 0.9770 - val_loss: 8.2144 - val_acc: 0.3301 - val_top_k_categorical_accuracy: 0.6188 - _timestamp: 1664970755.0000 - _runtime: 6626.0000\n",
      "Epoch 39/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 0.5373 - acc: 0.8324 - top_k_categorical_accuracy: 0.9816 - val_loss: 13.1499 - val_acc: 0.3404 - val_top_k_categorical_accuracy: 0.6287 - _timestamp: 1664970928.0000 - _runtime: 6799.0000\n",
      "Epoch 40/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.4790 - acc: 0.8487 - top_k_categorical_accuracy: 0.9859 - val_loss: 6.1703 - val_acc: 0.3316 - val_top_k_categorical_accuracy: 0.6284 - _timestamp: 1664971100.0000 - _runtime: 6971.0000\n",
      "Epoch 41/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.4567 - acc: 0.8571 - top_k_categorical_accuracy: 0.9880 - val_loss: 25.4292 - val_acc: 0.3321 - val_top_k_categorical_accuracy: 0.6278 - _timestamp: 1664971273.0000 - _runtime: 7144.0000\n",
      "Epoch 42/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.4555 - acc: 0.8558 - top_k_categorical_accuracy: 0.9875 - val_loss: 34.2102 - val_acc: 0.3315 - val_top_k_categorical_accuracy: 0.6260 - _timestamp: 1664971446.0000 - _runtime: 7317.0000\n",
      "Epoch 43/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 0.4141 - acc: 0.8701 - top_k_categorical_accuracy: 0.9900 - val_loss: 64.9689 - val_acc: 0.3311 - val_top_k_categorical_accuracy: 0.6169 - _timestamp: 1664971618.0000 - _runtime: 7489.0000\n",
      "Epoch 44/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 0.4057 - acc: 0.8737 - top_k_categorical_accuracy: 0.9905 - val_loss: 8.0819 - val_acc: 0.3371 - val_top_k_categorical_accuracy: 0.6267 - _timestamp: 1664971791.0000 - _runtime: 7662.0000\n",
      "Epoch 45/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.3869 - acc: 0.8788 - top_k_categorical_accuracy: 0.9921 - val_loss: 11.5900 - val_acc: 0.3423 - val_top_k_categorical_accuracy: 0.6266 - _timestamp: 1664971963.0000 - _runtime: 7834.0000\n",
      "Epoch 46/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.3993 - acc: 0.8758 - top_k_categorical_accuracy: 0.9912 - val_loss: 22.9906 - val_acc: 0.3368 - val_top_k_categorical_accuracy: 0.6230 - _timestamp: 1664972136.0000 - _runtime: 8007.0000\n",
      "Epoch 47/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 0.3304 - acc: 0.8939 - top_k_categorical_accuracy: 0.9949 - val_loss: 11.8216 - val_acc: 0.3433 - val_top_k_categorical_accuracy: 0.6305 - _timestamp: 1664972308.0000 - _runtime: 8179.0000\n",
      "Epoch 48/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.3425 - acc: 0.8923 - top_k_categorical_accuracy: 0.9942 - val_loss: 866.3348 - val_acc: 0.3328 - val_top_k_categorical_accuracy: 0.6269 - _timestamp: 1664972481.0000 - _runtime: 8352.0000\n",
      "Epoch 49/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.3387 - acc: 0.8939 - top_k_categorical_accuracy: 0.9940 - val_loss: 6.8608 - val_acc: 0.3403 - val_top_k_categorical_accuracy: 0.6304 - _timestamp: 1664972654.0000 - _runtime: 8525.0000\n",
      "Epoch 50/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.3064 - acc: 0.9046 - top_k_categorical_accuracy: 0.9956 - val_loss: 17.6313 - val_acc: 0.3399 - val_top_k_categorical_accuracy: 0.6238 - _timestamp: 1664972826.0000 - _runtime: 8697.0000\n",
      "Epoch 51/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.3000 - acc: 0.9068 - top_k_categorical_accuracy: 0.9954 - val_loss: 6.8983 - val_acc: 0.3426 - val_top_k_categorical_accuracy: 0.6299 - _timestamp: 1664972999.0000 - _runtime: 8870.0000\n",
      "Epoch 52/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.3102 - acc: 0.9039 - top_k_categorical_accuracy: 0.9954 - val_loss: 9.1823 - val_acc: 0.3423 - val_top_k_categorical_accuracy: 0.6276 - _timestamp: 1664973172.0000 - _runtime: 9043.0000\n",
      "Epoch 53/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.2973 - acc: 0.9093 - top_k_categorical_accuracy: 0.9956 - val_loss: 7.9733 - val_acc: 0.3462 - val_top_k_categorical_accuracy: 0.6349 - _timestamp: 1664973345.0000 - _runtime: 9216.0000\n",
      "Epoch 54/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.3773 - acc: 0.8847 - top_k_categorical_accuracy: 0.9926 - val_loss: 820.0096 - val_acc: 0.3360 - val_top_k_categorical_accuracy: 0.6264 - _timestamp: 1664973517.0000 - _runtime: 9388.0000\n",
      "Epoch 55/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.2401 - acc: 0.9257 - top_k_categorical_accuracy: 0.9968 - val_loss: 116.0503 - val_acc: 0.3340 - val_top_k_categorical_accuracy: 0.6381 - _timestamp: 1664973690.0000 - _runtime: 9561.0000\n",
      "Epoch 56/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.2716 - acc: 0.9186 - top_k_categorical_accuracy: 0.9961 - val_loss: 12.1800 - val_acc: 0.3432 - val_top_k_categorical_accuracy: 0.6252 - _timestamp: 1664973863.0000 - _runtime: 9734.0000\n",
      "Epoch 57/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.2792 - acc: 0.9149 - top_k_categorical_accuracy: 0.9962 - val_loss: 37.9111 - val_acc: 0.3485 - val_top_k_categorical_accuracy: 0.6354 - _timestamp: 1664974036.0000 - _runtime: 9907.0000\n",
      "Epoch 58/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.2411 - acc: 0.9273 - top_k_categorical_accuracy: 0.9971 - val_loss: 84.7145 - val_acc: 0.3517 - val_top_k_categorical_accuracy: 0.6329 - _timestamp: 1664974209.0000 - _runtime: 10080.0000\n",
      "Epoch 59/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.2631 - acc: 0.9201 - top_k_categorical_accuracy: 0.9967 - val_loss: 39.3391 - val_acc: 0.3398 - val_top_k_categorical_accuracy: 0.6290 - _timestamp: 1664974382.0000 - _runtime: 10253.0000\n",
      "Epoch 60/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.2522 - acc: 0.9238 - top_k_categorical_accuracy: 0.9972 - val_loss: 21.0444 - val_acc: 0.3327 - val_top_k_categorical_accuracy: 0.6214 - _timestamp: 1664974554.0000 - _runtime: 10425.0000\n"
     ]
    }
   ],
   "source": [
    "# Dual\n",
    "D_vgg_16.compile(loss=categorical_crossentropy, \n",
    "              optimizer=Adam(learning_rate=0.001), \n",
    "              metrics=['acc','top_k_categorical_accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "history = D_vgg_16.fit(X_train,  # 학습할 데이터\n",
    "                    y_train,  # 학습할 레이블\n",
    "                    epochs=EPOCHS,  # 전체 학습할 횟수\n",
    "                    batch_size=BATCH_SIZE,  # 배치 사이즈\n",
    "                    use_multiprocessing=True,\n",
    "                    validation_data=(X_valid, y_valid), # 검증 데이터로 확인\n",
    "                    callbacks=[wandbcallback_D]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a685a9b5-2043-4564-ad4a-834e818ea04f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "2500/2500 [==============================] - 200s 71ms/step - loss: 4.2150 - acc: 0.0472 - top_k_categorical_accuracy: 0.1931 - val_loss: 4.0740 - val_acc: 0.0643 - val_top_k_categorical_accuracy: 0.2382 - _timestamp: 1665023217.0000 - _runtime: 267.0000\n",
      "Epoch 2/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 3.8942 - acc: 0.0913 - top_k_categorical_accuracy: 0.2942 - val_loss: 3.8199 - val_acc: 0.1081 - val_top_k_categorical_accuracy: 0.3193 - _timestamp: 1665023390.0000 - _runtime: 440.0000\n",
      "Epoch 3/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 3.7063 - acc: 0.1187 - top_k_categorical_accuracy: 0.3538 - val_loss: 3.6204 - val_acc: 0.1416 - val_top_k_categorical_accuracy: 0.3782 - _timestamp: 1665023562.0000 - _runtime: 612.0000\n",
      "Epoch 4/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 3.5462 - acc: 0.1457 - top_k_categorical_accuracy: 0.3997 - val_loss: 3.4955 - val_acc: 0.1483 - val_top_k_categorical_accuracy: 0.4134 - _timestamp: 1665023735.0000 - _runtime: 785.0000\n",
      "Epoch 5/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 3.4086 - acc: 0.1676 - top_k_categorical_accuracy: 0.4390 - val_loss: 3.6459 - val_acc: 0.1553 - val_top_k_categorical_accuracy: 0.4249 - _timestamp: 1665023907.0000 - _runtime: 957.0000\n",
      "Epoch 6/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 3.2457 - acc: 0.1931 - top_k_categorical_accuracy: 0.4825 - val_loss: 3.2508 - val_acc: 0.2007 - val_top_k_categorical_accuracy: 0.4987 - _timestamp: 1665024079.0000 - _runtime: 1129.0000\n",
      "Epoch 7/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 3.1184 - acc: 0.2171 - top_k_categorical_accuracy: 0.5185 - val_loss: 4.4811 - val_acc: 0.2266 - val_top_k_categorical_accuracy: 0.5304 - _timestamp: 1665024252.0000 - _runtime: 1302.0000\n",
      "Epoch 8/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 3.0530 - acc: 0.2323 - top_k_categorical_accuracy: 0.5298 - val_loss: 3.1275 - val_acc: 0.2360 - val_top_k_categorical_accuracy: 0.5372 - _timestamp: 1665024424.0000 - _runtime: 1474.0000\n",
      "Epoch 9/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 2.8497 - acc: 0.2683 - top_k_categorical_accuracy: 0.5814 - val_loss: 3.1178 - val_acc: 0.2584 - val_top_k_categorical_accuracy: 0.5711 - _timestamp: 1665024596.0000 - _runtime: 1646.0000\n",
      "Epoch 10/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 3.1139 - acc: 0.2230 - top_k_categorical_accuracy: 0.5172 - val_loss: 99.1230 - val_acc: 0.2381 - val_top_k_categorical_accuracy: 0.5337 - _timestamp: 1665024769.0000 - _runtime: 1819.0000\n",
      "Epoch 11/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 2.8542 - acc: 0.2723 - top_k_categorical_accuracy: 0.5805 - val_loss: 6.8848 - val_acc: 0.2783 - val_top_k_categorical_accuracy: 0.5886 - _timestamp: 1665024941.0000 - _runtime: 1991.0000\n",
      "Epoch 12/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 2.8573 - acc: 0.2714 - top_k_categorical_accuracy: 0.5818 - val_loss: 3.3948 - val_acc: 0.2801 - val_top_k_categorical_accuracy: 0.6050 - _timestamp: 1665025113.0000 - _runtime: 2163.0000\n",
      "Epoch 13/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 2.6289 - acc: 0.3183 - top_k_categorical_accuracy: 0.6337 - val_loss: 25.4183 - val_acc: 0.2890 - val_top_k_categorical_accuracy: 0.6070 - _timestamp: 1665025285.0000 - _runtime: 2335.0000\n",
      "Epoch 14/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 2.4893 - acc: 0.3438 - top_k_categorical_accuracy: 0.6672 - val_loss: 112.0734 - val_acc: 0.3175 - val_top_k_categorical_accuracy: 0.6333 - _timestamp: 1665025458.0000 - _runtime: 2508.0000\n",
      "Epoch 15/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 2.3823 - acc: 0.3650 - top_k_categorical_accuracy: 0.6897 - val_loss: 53.5032 - val_acc: 0.3240 - val_top_k_categorical_accuracy: 0.6514 - _timestamp: 1665025630.0000 - _runtime: 2680.0000\n",
      "Epoch 16/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 2.3096 - acc: 0.3827 - top_k_categorical_accuracy: 0.7055 - val_loss: 11.9656 - val_acc: 0.3423 - val_top_k_categorical_accuracy: 0.6687 - _timestamp: 1665025802.0000 - _runtime: 2852.0000\n",
      "Epoch 17/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 2.3630 - acc: 0.3706 - top_k_categorical_accuracy: 0.6952 - val_loss: 6.3678 - val_acc: 0.3549 - val_top_k_categorical_accuracy: 0.6740 - _timestamp: 1665025975.0000 - _runtime: 3025.0000\n",
      "Epoch 18/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 2.1467 - acc: 0.4141 - top_k_categorical_accuracy: 0.7382 - val_loss: 12.0302 - val_acc: 0.3399 - val_top_k_categorical_accuracy: 0.6553 - _timestamp: 1665026148.0000 - _runtime: 3198.0000\n",
      "Epoch 19/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 2.0505 - acc: 0.4379 - top_k_categorical_accuracy: 0.7571 - val_loss: 9.7242 - val_acc: 0.3315 - val_top_k_categorical_accuracy: 0.6584 - _timestamp: 1665026320.0000 - _runtime: 3370.0000\n",
      "Epoch 20/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 2.0158 - acc: 0.4473 - top_k_categorical_accuracy: 0.7656 - val_loss: 18.1210 - val_acc: 0.3841 - val_top_k_categorical_accuracy: 0.6964 - _timestamp: 1665026493.0000 - _runtime: 3543.0000\n",
      "Epoch 21/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 1.8415 - acc: 0.4851 - top_k_categorical_accuracy: 0.7978 - val_loss: 18.6480 - val_acc: 0.3738 - val_top_k_categorical_accuracy: 0.6930 - _timestamp: 1665026666.0000 - _runtime: 3716.0000\n",
      "Epoch 22/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 1.8325 - acc: 0.4904 - top_k_categorical_accuracy: 0.7982 - val_loss: 6.7454 - val_acc: 0.3695 - val_top_k_categorical_accuracy: 0.6874 - _timestamp: 1665026839.0000 - _runtime: 3889.0000\n",
      "Epoch 23/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 1.7136 - acc: 0.5145 - top_k_categorical_accuracy: 0.8191 - val_loss: 351.3832 - val_acc: 0.3881 - val_top_k_categorical_accuracy: 0.7023 - _timestamp: 1665027011.0000 - _runtime: 4061.0000\n",
      "Epoch 24/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 1.5898 - acc: 0.5426 - top_k_categorical_accuracy: 0.8441 - val_loss: 25.4546 - val_acc: 0.3844 - val_top_k_categorical_accuracy: 0.7002 - _timestamp: 1665027184.0000 - _runtime: 4234.0000\n",
      "Epoch 25/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 1.5121 - acc: 0.5628 - top_k_categorical_accuracy: 0.8572 - val_loss: 115.3093 - val_acc: 0.3862 - val_top_k_categorical_accuracy: 0.6955 - _timestamp: 1665027357.0000 - _runtime: 4407.0000\n",
      "Epoch 26/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 1.4042 - acc: 0.5891 - top_k_categorical_accuracy: 0.8744 - val_loss: 836.3231 - val_acc: 0.3866 - val_top_k_categorical_accuracy: 0.6977 - _timestamp: 1665027529.0000 - _runtime: 4579.0000\n",
      "Epoch 27/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 1.2766 - acc: 0.6234 - top_k_categorical_accuracy: 0.8951 - val_loss: 4.1082 - val_acc: 0.3852 - val_top_k_categorical_accuracy: 0.6925 - _timestamp: 1665027701.0000 - _runtime: 4751.0000\n",
      "Epoch 28/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 1.2954 - acc: 0.6224 - top_k_categorical_accuracy: 0.8904 - val_loss: 110.0181 - val_acc: 0.3970 - val_top_k_categorical_accuracy: 0.7055 - _timestamp: 1665027873.0000 - _runtime: 4923.0000\n",
      "Epoch 29/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 1.1469 - acc: 0.6533 - top_k_categorical_accuracy: 0.9115 - val_loss: 12.8744 - val_acc: 0.3994 - val_top_k_categorical_accuracy: 0.7065 - _timestamp: 1665028046.0000 - _runtime: 5096.0000\n",
      "Epoch 30/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 1.0616 - acc: 0.6818 - top_k_categorical_accuracy: 0.9234 - val_loss: 82.4087 - val_acc: 0.3876 - val_top_k_categorical_accuracy: 0.6887 - _timestamp: 1665028220.0000 - _runtime: 5270.0000\n",
      "Epoch 31/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 0.8870 - acc: 0.7290 - top_k_categorical_accuracy: 0.9458 - val_loss: 26.9593 - val_acc: 0.3948 - val_top_k_categorical_accuracy: 0.7064 - _timestamp: 1665028392.0000 - _runtime: 5442.0000\n",
      "Epoch 32/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 0.8033 - acc: 0.7530 - top_k_categorical_accuracy: 0.9549 - val_loss: 8.2045 - val_acc: 0.3974 - val_top_k_categorical_accuracy: 0.7018 - _timestamp: 1665028564.0000 - _runtime: 5614.0000\n",
      "Epoch 33/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 0.8048 - acc: 0.7538 - top_k_categorical_accuracy: 0.9578 - val_loss: 27.0733 - val_acc: 0.3822 - val_top_k_categorical_accuracy: 0.6852 - _timestamp: 1665028736.0000 - _runtime: 5786.0000\n",
      "Epoch 34/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 0.6600 - acc: 0.7926 - top_k_categorical_accuracy: 0.9703 - val_loss: 1202.5159 - val_acc: 0.3797 - val_top_k_categorical_accuracy: 0.6840 - _timestamp: 1665028908.0000 - _runtime: 5958.0000\n",
      "Epoch 35/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 0.6208 - acc: 0.8070 - top_k_categorical_accuracy: 0.9746 - val_loss: 2510.1702 - val_acc: 0.3831 - val_top_k_categorical_accuracy: 0.6799 - _timestamp: 1665029079.0000 - _runtime: 6129.0000\n",
      "Epoch 36/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 0.5770 - acc: 0.8197 - top_k_categorical_accuracy: 0.9786 - val_loss: 61.9251 - val_acc: 0.3844 - val_top_k_categorical_accuracy: 0.6916 - _timestamp: 1665029252.0000 - _runtime: 6302.0000\n",
      "Epoch 37/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 0.5621 - acc: 0.8237 - top_k_categorical_accuracy: 0.9804 - val_loss: 5.2810 - val_acc: 0.3876 - val_top_k_categorical_accuracy: 0.6834 - _timestamp: 1665029424.0000 - _runtime: 6474.0000\n",
      "Epoch 38/60\n",
      "2500/2500 [==============================] - 174s 69ms/step - loss: 0.4922 - acc: 0.8449 - top_k_categorical_accuracy: 0.9843 - val_loss: 9.4120 - val_acc: 0.4011 - val_top_k_categorical_accuracy: 0.7048 - _timestamp: 1665029596.0000 - _runtime: 6646.0000\n",
      "Epoch 39/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 0.4500 - acc: 0.8566 - top_k_categorical_accuracy: 0.9876 - val_loss: 17.0349 - val_acc: 0.3911 - val_top_k_categorical_accuracy: 0.6889 - _timestamp: 1665029770.0000 - _runtime: 6820.0000\n",
      "Epoch 40/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 0.4644 - acc: 0.8565 - top_k_categorical_accuracy: 0.9869 - val_loss: 10.9390 - val_acc: 0.3874 - val_top_k_categorical_accuracy: 0.6845 - _timestamp: 1665029942.0000 - _runtime: 6992.0000\n",
      "Epoch 41/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 0.4344 - acc: 0.8633 - top_k_categorical_accuracy: 0.9893 - val_loss: 32.5639 - val_acc: 0.3859 - val_top_k_categorical_accuracy: 0.6856 - _timestamp: 1665030114.0000 - _runtime: 7164.0000\n",
      "Epoch 42/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.4133 - acc: 0.8698 - top_k_categorical_accuracy: 0.9898 - val_loss: 1577.5026 - val_acc: 0.3913 - val_top_k_categorical_accuracy: 0.6875 - _timestamp: 1665030287.0000 - _runtime: 7337.0000\n",
      "Epoch 43/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.4115 - acc: 0.8740 - top_k_categorical_accuracy: 0.9883 - val_loss: 305.8036 - val_acc: 0.3820 - val_top_k_categorical_accuracy: 0.6797 - _timestamp: 1665030460.0000 - _runtime: 7510.0000\n",
      "Epoch 44/60\n",
      "2500/2500 [==============================] - 186s 75ms/step - loss: 0.3682 - acc: 0.8847 - top_k_categorical_accuracy: 0.9922 - val_loss: 60.8922 - val_acc: 0.3948 - val_top_k_categorical_accuracy: 0.6864 - _timestamp: 1665030646.0000 - _runtime: 7696.0000\n",
      "Epoch 45/60\n",
      "2500/2500 [==============================] - 200s 80ms/step - loss: 0.3057 - acc: 0.9030 - top_k_categorical_accuracy: 0.9949 - val_loss: 14.6340 - val_acc: 0.3965 - val_top_k_categorical_accuracy: 0.6868 - _timestamp: 1665030846.0000 - _runtime: 7896.0000\n",
      "Epoch 46/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.3264 - acc: 0.8968 - top_k_categorical_accuracy: 0.9945 - val_loss: 87.1656 - val_acc: 0.3950 - val_top_k_categorical_accuracy: 0.6887 - _timestamp: 1665031018.0000 - _runtime: 8068.0000\n",
      "Epoch 47/60\n",
      "2500/2500 [==============================] - 173s 69ms/step - loss: 0.3176 - acc: 0.9013 - top_k_categorical_accuracy: 0.9940 - val_loss: 38.2536 - val_acc: 0.3771 - val_top_k_categorical_accuracy: 0.6743 - _timestamp: 1665031191.0000 - _runtime: 8241.0000\n",
      "Epoch 48/60\n",
      "2500/2500 [==============================] - 174s 69ms/step - loss: 0.3014 - acc: 0.9047 - top_k_categorical_accuracy: 0.9950 - val_loss: 39.8074 - val_acc: 0.3891 - val_top_k_categorical_accuracy: 0.6865 - _timestamp: 1665031364.0000 - _runtime: 8414.0000\n",
      "Epoch 49/60\n",
      "2500/2500 [==============================] - 203s 81ms/step - loss: 0.3145 - acc: 0.9054 - top_k_categorical_accuracy: 0.9948 - val_loss: 1133.3571 - val_acc: 0.3924 - val_top_k_categorical_accuracy: 0.6886 - _timestamp: 1665031567.0000 - _runtime: 8617.0000\n",
      "Epoch 50/60\n",
      "2500/2500 [==============================] - 180s 72ms/step - loss: 0.2697 - acc: 0.9170 - top_k_categorical_accuracy: 0.9959 - val_loss: 22.4244 - val_acc: 0.3911 - val_top_k_categorical_accuracy: 0.6836 - _timestamp: 1665031747.0000 - _runtime: 8797.0000\n",
      "Epoch 51/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 0.2846 - acc: 0.9133 - top_k_categorical_accuracy: 0.9954 - val_loss: 2018.4962 - val_acc: 0.3854 - val_top_k_categorical_accuracy: 0.6827 - _timestamp: 1665031919.0000 - _runtime: 8969.0000\n",
      "Epoch 52/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 0.2794 - acc: 0.9149 - top_k_categorical_accuracy: 0.9955 - val_loss: 8151.7280 - val_acc: 0.3986 - val_top_k_categorical_accuracy: 0.6884 - _timestamp: 1665032091.0000 - _runtime: 9141.0000\n",
      "Epoch 53/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 0.2588 - acc: 0.9190 - top_k_categorical_accuracy: 0.9959 - val_loss: 8192.6387 - val_acc: 0.3942 - val_top_k_categorical_accuracy: 0.6780 - _timestamp: 1665032263.0000 - _runtime: 9313.0000\n",
      "Epoch 54/60\n",
      "2500/2500 [==============================] - 185s 74ms/step - loss: 0.2668 - acc: 0.9201 - top_k_categorical_accuracy: 0.9959 - val_loss: 292.8522 - val_acc: 0.3767 - val_top_k_categorical_accuracy: 0.6777 - _timestamp: 1665032448.0000 - _runtime: 9498.0000\n",
      "Epoch 55/60\n",
      "2500/2500 [==============================] - 202s 81ms/step - loss: 0.2649 - acc: 0.9212 - top_k_categorical_accuracy: 0.9961 - val_loss: 18750.0605 - val_acc: 0.3993 - val_top_k_categorical_accuracy: 0.6898 - _timestamp: 1665032650.0000 - _runtime: 9700.0000\n",
      "Epoch 56/60\n",
      "2500/2500 [==============================] - 178s 71ms/step - loss: 0.2409 - acc: 0.9265 - top_k_categorical_accuracy: 0.9977 - val_loss: 74.8928 - val_acc: 0.3921 - val_top_k_categorical_accuracy: 0.6767 - _timestamp: 1665032827.0000 - _runtime: 9877.0000\n",
      "Epoch 57/60\n",
      "2500/2500 [==============================] - 204s 82ms/step - loss: 0.2388 - acc: 0.9281 - top_k_categorical_accuracy: 0.9967 - val_loss: 30.4322 - val_acc: 0.3846 - val_top_k_categorical_accuracy: 0.6732 - _timestamp: 1665033031.0000 - _runtime: 10081.0000\n",
      "Epoch 58/60\n",
      "2500/2500 [==============================] - 178s 71ms/step - loss: 0.2373 - acc: 0.9295 - top_k_categorical_accuracy: 0.9970 - val_loss: 27.6105 - val_acc: 0.3892 - val_top_k_categorical_accuracy: 0.6840 - _timestamp: 1665033209.0000 - _runtime: 10259.0000\n",
      "Epoch 59/60\n",
      "2500/2500 [==============================] - 172s 69ms/step - loss: 0.2446 - acc: 0.9276 - top_k_categorical_accuracy: 0.9970 - val_loss: 200.4645 - val_acc: 0.3872 - val_top_k_categorical_accuracy: 0.6810 - _timestamp: 1665033381.0000 - _runtime: 10431.0000\n",
      "Epoch 60/60\n",
      "2500/2500 [==============================] - 201s 80ms/step - loss: 0.2504 - acc: 0.9258 - top_k_categorical_accuracy: 0.9957 - val_loss: 16205.4912 - val_acc: 0.3946 - val_top_k_categorical_accuracy: 0.6853 - _timestamp: 1665033582.0000 - _runtime: 10632.0000\n"
     ]
    }
   ],
   "source": [
    "# Dual 2\n",
    "D2_vgg_16.compile(loss=categorical_crossentropy, \n",
    "              optimizer=Adam(learning_rate=0.001), \n",
    "              metrics=['acc','top_k_categorical_accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "history_2 = D2_vgg_16.fit(X_train,  # 학습할 데이터\n",
    "                    y_train,  # 학습할 레이블\n",
    "                    epochs=EPOCHS,  # 전체 학습할 횟수\n",
    "                    batch_size=BATCH_SIZE,  # 배치 사이즈\n",
    "                    use_multiprocessing=True,\n",
    "                    validation_data=(X_valid, y_valid), # 검증 데이터로 확인\n",
    "                    callbacks=[wandbcallback_D]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fef9dd2f-d1d8-4efb-9c25-7b32d6c62d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▁▂▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>top_k_categorical_accuracy</td><td>▁▂▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇████████████████████</td></tr><tr><td>val_acc</td><td>▁▂▃▃▄▅▅▅▆▆▇▇▇█▇█████████████████████████</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▄▄█▁▁▇</td></tr><tr><td>val_top_k_categorical_accuracy</td><td>▁▂▄▄▅▅▅▆▇▇▇█▇███████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.92577</td></tr><tr><td>best_epoch</td><td>37</td></tr><tr><td>best_val_acc</td><td>0.4011</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>loss</td><td>0.25039</td></tr><tr><td>top_k_categorical_accuracy</td><td>0.99568</td></tr><tr><td>val_acc</td><td>0.3946</td></tr><tr><td>val_loss</td><td>16205.49121</td></tr><tr><td>val_top_k_categorical_accuracy</td><td>0.6853</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">DualPooing2</strong>: <a href=\"https://wandb.ai/diplab/DualPooing/runs/1cfx0hby\" target=\"_blank\">https://wandb.ai/diplab/DualPooing/runs/1cfx0hby</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221006_112216-1cfx0hby/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63646e24-7d64-4bb7-8c96-1ebac6ab5d9b",
   "metadata": {},
   "source": [
    "# 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a4e661bb-f0fe-4b41-822b-21fce8e00d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 2s 4ms/step - loss: 5.4289 - acc: 0.4285 - top_k_categorical_accuracy: 0.7055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.42888069152832, 0.4284999966621399, 0.7055000066757202]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_16.evaluate(X_test, y_test, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e01cc07f-2cb7-4a77-80f9-20ce01e2d744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 12s 18ms/step - loss: 7.7066 - acc: 0.3414 - top_k_categorical_accuracy: 0.6294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.706627368927002, 0.34139999747276306, 0.6294000148773193]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_vgg_16.evaluate(X_test, y_test, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37833bed-6074-4bdf-994f-fe7ab0564da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 11s 18ms/step - loss: 399.3070 - acc: 0.4048 - top_k_categorical_accuracy: 0.6913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[399.3070373535156, 0.4047999978065491, 0.6912999749183655]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D2_vgg_16.evaluate(X_test, y_test, batch_size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6d5d2d-fc89-42ff-84eb-ae48ac6b0777",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 메모"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe17507-163f-4d09-919c-17c4c85ce4a6",
   "metadata": {},
   "source": [
    "* Inductive bias를 비교하기위해 Test data를 써보면 어떨까"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a952e5c0-87c9-4d5d-b8f2-009cec57a19d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 창고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca8ee5e-86c2-42ad-b089-bd3cd9a915ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1",
   "language": "python",
   "name": "tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
